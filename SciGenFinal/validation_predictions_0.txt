< cap > table 2 : throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ‘ s iterative approach , with the large movie review dataset . the recursive approach performs the best on inference with efficient parallel execution of tree nodes , while the folding technique shows better performance on training thanks to its gpu exploitation . < r > < c > throughput ( instances / s ) batch size < batch size ( c > batch size ( c ) inference inference throughput throughput training throughput inference < b > inference overflow throughput overflow overflow inference ( b ) overflow < b ) throughput ( < b > overflow ( < c > ) overflow ( b ) ) throughput ( > b > ) throughput ( ~ b ) < cap > figure 2 . throughput for processing the tree lstm model on our recursive framework , fold ' s folding technique , and tensorflow ' s iterative approach , and our iteration approach . table 2 . the throughput of processing the recursive model on our recursively - folding framework . < c / c > recur recur iter recur inference recur retrieval inference retriever recur throughput < b / b > iter inference < / c > iter < f > fold < f / f > iter retrievance < f / > recur < / f > < / cap > figure 3 . the recur - fold - iter - recur - retriever - recursive - recursive - recurring - recurrent - fractional - iteration - inference - training - throughput - throughput - training throughput . < r > < c > 1 . 5 < c > . 2 . 5 < c > 3 . 2 < c + 4 . 0 < c & c > 4 . 6 < c < 5 . 5 < / c > . 5 . 5 < / c > r > 2 . 8 < c > : 9 . 4 < c > ) 16 . 2 < c > ) 37 . 6 < c > . 54 . 9 < c > " 61 . 0 < r > 5 . 6 < / c > . 54 . 9 > 52 . 7 < cap
table 1 . table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 , because there is only a small room of performance improvement left , w . r . t parallelization . < r > < c > batch size < b > throughput ( instances / s ) linear < batch size ( bits ) < bits / s > balanced < batches / s ) balanced ( batches ) ( batch / s ) * linear ( bouts / s ) * balanced ( bs ) ( bs / s * ) balanced ( bs ) ( bss / s * ) linear ( bss ) ( sbs / sbs ) ( bcs / bcs ) balanced < d > < d < c > balanced ( ds ) ( dss / d < cap ) linear ( dbs ) < dbs > < cap ) balanced ( < dbs > ) ( dss / cap ) dbs ( dcs ) ( dcs / dcs ) dsb ( dcs / dcs ) dbc ( dcs ) / dcs ( dcs ) throughput for each dataset . < b > ( batch ) ( dbs ) ( c ) < t > < b ) < c > ( b ) ( t ) < a > < t ) 1 < c . 2 < c > . 22 . 7 < c > " 27 . 6 < r > ( c ) 3 . 3 < c > ) 7 . 1 < c + 45 . 6 ( t - t ) 5 . 2 . 7 ( c > 83 . 6 ( t ) 7 . 2 ( t + t ) 10 . 6 < t > 13 . 6 < / t > 15 . 6
table 2 : hyper parameter optimization results for each model with different representation . the max pooling strategy consistently performs better in all model variations . feature maps < c > [ bold ] hyper parameters activation func . < r > [ c > conll08 ( avg . in 5 - fold ) with optimal values < e > [ cap > colll08 < bold ] f1 . ( avg . ) with default values < f > [ fold ] f2 ( avg . ) . < cap > f1 . < bold ) f2 . < cap > . < cap > f1 . < cap > f2 . < cap > , f2 < cap > , f3 < cap > . table 3 : hyper parameters for all models with different representations . < t > [ t > hyper parameters l2 v1 . 2 . 3 < c / 5 < c + 1 < c - 1 > 0 . 79e - 03 < c > " 0 . 63e - 04 < c ' s . < c ] [ cap ] l2 v1 . 1 . 0 < c2 > 1 . 13e - 02 < c - " 1 . 13e - 02 " < c > 1 < c > " 1 . 15e + 01 < c " 1 . 83 < c ' " 1 . 05 < c ' 1 . 09 < c " 1 . 09 " < c > . < r > " < cap > " f2 . ( v1 . 3 . 3 ) with default value < f1 . ( v2 . 0 . 3 ) . < cap > > f1 ( v2 . ) < cap / > f2 ( v3 ) < cap " > f2 . ( v3 ) < cap > > f3 ( v4 ) . < r > [ cap > < cap ] f3 . ( v4 . 3 ) < / cap > v1 . ( v5 . 3 < / cap > ) < r > < f2 > f3 . ( v6 . 3 < v7 . 3 > ) f1 ( v8 . 1 ) f5 ( v9 . 2 ) f6 ( v10 . 0 ) f7 ( v11 . 2 ) ( f12 . 0 ) ( f13 . 1 ) ( f14 . 5 ) ( f15 . 1 ) ) f1 ( v10 . 2 ) ) f2 ( v12 . 2 ) < / cap ) f3 ( v14 . 1 ) - f5 ( v15 . 2 ) - f6 ( v17 . 0 ) ) f6 . ( v18 . 1 ) < / cap . < d > < c > [ cap ] f1 > f2
< cap > table 1 : effect of using the shortest dependency path on each relation type . < r > < c > [ bold ] relation ( in 5 - fold ) without sdp > < cap > < bold > best f1 ( in 10 - fold ) , with sdp < r > [ c > relation ( in f1 ) ( in f2 ) > < p > [ cap > [ p > ] [ cap ] < cap ] [ p < c > ] < p < r > < c > [ cap > ] [ cap ] [ cap ] < cap ] [ cap ] < / cap > > < p > [ p > ] [ p > > < / cap ] > < / p > < cap > < r > < b > [ bold ] [ cap > ] < / b > ( cap ) < cap > < / b > > < cap > [ c > ] [ bold [ cap ] ] < cap < b > ( cap ) [ cap ] [ b ] ( cap ) ] < cap [ b ( cap ) ] [ cap [ c ] ] [ cap < c ( cap ) ) [ cap < cap | cap ] | cap [ cap ] ) < cap ( cap ) [ cap ] # < cap # [ cap # ] [ cap # | cap ] ] < / cap # ] # < / cap | | cap | [ cap | ] [ cap | [ [ cap | ] ] | cap # [ [ cap # ] ] | cp | | cc | | ccc | | ct | | tc | | t | | v | | w | | x | | y | | z | | p | | f | | a | | r | | s | | b | | c | | g | | h | | d | | e | | l | | m | | n | | o | | u | | q | | i | | j | | | k | | so | | wh | | th | | st | | crypt | | transcript | | synopsis | | computer | | process | | request | | data | | value | | table | | results | | topic | | model - feature | | matter | | result | | title | | platform | | worldplatinum | | number | | name | | class | | type | | size | | parity | | description | | introduction | | extraction | | method | | definition | | value | | or | |
1 . < r > < c > [ empty ] < c / c > c - f1 100 % < c ' s f1 50 % < c > f1 100 % , < c : f1 50 % , f : f100 % , c : f 100 % , f - f 1 , c : c , f - c 100 % , c - c , c - d , c , d , f , e , f1 , f 1 , g , h , j , k , l , m , n , p , r , s , t , w , y , z , y - 3 : y < italic > c < / italic > , y - 2 : y < / italics > - 3 < c > < c > < bold > 50 . 35 < c < bold > 47 . 58 < / bold > < c > 47 . 31 < c > , 47 . 40 < / bold > , < c > < / bold > < r > < c > . < c > . < c > : < c > [ empty ] [ empty < c > ] < / c > < / r > < / c > . < / r > . < r > < c > . [ empty > < c > ] < c > , < c . . . ] < / r > < / c > . ( c ) < / c ) < r > < / r > ( c > ) < / c > ) < r > . [ c ] < / c ] ( c > < b ) < / b ) < b > < / b > [ b ] < b ] < / b ] < b > ( b ) < b ) ( b ) [ b ] ( c ) < r > < b > < / b > ( c > [ c ] [ b ] ( b ] ) ( b ) ( b ) ] ( c ) [ b ] - ( c ) ( c ) ] ( b ) [ c ] ( b ) ] ( b [ c ] ) ( b [ b ] ) ( b ) [ b ] [ c ] - ( b ) ] - ( b ) [ b ] [ b ] [ a ] ( a ] ( a ) ( a ) ( a ) [ a ] [ a ] < / a > ( a ) ] ( a [ a ] ) ( a ) ] ( a [ b ] ] ( a ] [ b ] ) ( a ) [ b ] ] ( a ] [ c ] [ c ] ] ( b ] [ d ] ] ( d ) ] ( d ) [ d ] [ e ] ( d ] [ f ] ( e ) [ f ] ( d ] [ g ] [ h ] ( e ) ] ( f ) [ f ] [ h ] [ i ] ( f ) ] ( f ) [ h ] [ j ] ( h ] [ k ] ( h ] [ l ] [ r ] [ r ] ( j ) ] (
r > < c > paragraph level acc . < r > [ empty ] < c + < c - f1 < c < c > [ c > c - f2 < c > . < c > < c > r - f3 < c > < / c > mst - parser < c > , < c > ( c > 31 . 17 < c > ) 22 . 72 < / c > 12 . 72 < c > 12 . 17 < / c > ) < c > [ empty ] [ empty > ] < r > . < mst - parser < c , < c > : < c > " 0 < c . 23 < c & c > 0 . 29 < c # 0 . 59 < c * 0 . 90 < c | 0 . 71 < c * * 0 . 72 ( c > 2 . 17 ) < c ~ 0 . 34 < c - - 0 . 23 ( c ) < r . < c / c > 1 . 03 < c ; 4 . 03 ( c > ) 1 . 59 ( c + ) < c : 0 . 22 ( c : 1 . 23 ) < c > 6 . 71 ( c ) : 0 . 32 ( c ) ; 0 . 24 ( c ; 0 . 25 ) ( c ) , 0 . 01 ( c ) - 0 . 17 ( c ) . < r > , < msp - parser < c , < c > , < c > : < r > r > < mps - parser < / c > < / msp > < c > 22 . 32 < / c > , 0 . 72 < / c > , 1 . 23 < / c > : 0 . 29 < / c > . < r > , > msp - parser < c | < c > . < / mps > < r , > mps - parser < / c ) , < mps > , < msp > , < r , > , < p > , < s > , < t > , < v > , < w > , < y > , < z > , < f > , < g > , < h > , < a > , < b > , < d > , < e , < f , > < g , < h , < a , < m , < b , < t , < v , < u , < w , < d , < e > , > < h > < f > < / h > < / j > < / p > < / r > < / r > < mst > < c . < paragraph level c - f1 . < / paragraph > paragraph - level f1 . < / paragraph ) paragraph - level f1 - level - 1 - 2 - 3 - 4 - 5
table 4 . table 4 : c - f1 ( 100 % ) in % for the two indicated systems ; essay vs . paragraph . note that the mean performances are lower than the majority performances over the runs given in table 2 . paragraph level . < r > < c > [ empty ] < cap > lstm - parser < p > < cap > < cap - parser < c > c - c1 < c - c2 < c + c - d1 < cap + c + d1 < cap + d2 < cap - d3 < c + f1 < c - f2 < c - ) f1 < / cap - f3 < cap > c - b1 < b2 < b3 < b4 < b5 < b6 < b7 < b8 < b9 < b10 < b11 < b12 < b13 < b14 < b15 < b16 < b17 < b18 < b19 < b20 < b21 < b22 < b23 < b24 < b25 < b26 < b27 < b28 < b29 < b30 < b31 < b32 < b33 < b34 < b35 < b36 < b37 < b38 < b39 < b40 < b41 < b42 < b43 < b44 < b45 < b46 < b47 < b48 < b49 < b50 < b51 < b52 < b53 < b54 < b55 < b56 < b57 < b58 < b59 < b60 < b61 < b62 < b63 < b64 < b65 < b66 < b67 < b68 < b69 < b70 < b71 < b72 < b73 < b74 < b75 < b76 < b77 < b78 < b79 < b80 < b81 < b82 < b83 < b84 < b85 < b88 < b89 < b90 < b91 < b94 < b95 < b96 < b98 < b99 < b100 < b101 < b102 < b103 < b104 < b105 < b110 < b111 < b112 < b113 < b114 < b115 < b131 < b133 < b134 < b135 < b136 < b139 < b141 < b143 < b144 < b145 < b146 < b147 < b148 < b149 < b155 < b156 < b167 < b168
< c > [ bold ] cleaned < c > sc - lstm 0 . 8181 < r > 0 . 6016 < bold ] 0 . 7623 < bold 1 . 01 < r > 0 . 7 < c2 0 . 9 < r . 24 < r > . < r > : 0 . 5 < r : 0 . 0 < c > . 0 . 1 < c . 1 . < r > < r > 1 . 0 . 0 < / r > < r > , 0 . 2 < r < r > 0 . 2 . 0 < r > . 0 . 1 < / r . 1 < r . 2 < r3 < r4 < r5 < r6 < r7 < r8 < r9 < r10 < r11 < r12 < r13 < r14 < r15 < r16 < r17 < r18 < r19 < r20 < r21 < r22 < r23 < r24 < r25 < r26 < r28 < r29 < r30 < r31 < r32 < r33 < r34 < r35 < r36 < r37 < r38 < r39 < r40 < r41 < r42 < r43 < r44 < r45 < r46 < r47 < r48 < r49 < r50 < r51 < r52 < r53 < r54 < r55 < r56 < r57 < r58 < r59 < r60 < r61 < r62 < r63 < r64 < r69 < r70 < r74 < r75 < r80 < r85 < r86 < r88 < r89 < r90 < r91 < r92 < r93 < r94 < r95 < r96 < r98 < r99 < r100 < r101 < r102 < r103 < r104 < r105 < r106 < r107 < r108 < r109 < r110 < r113 < r114 < r115 < r116 < r117 < r118 < r129 < r130 < r131 < r134 < r135 < r136 < r137 < r138 < r139 < r140 < r141 < r149 < r150 < r155 < r156 < r157 < r158 < r168 < r169 < r170 < r181 < r178 < r179 < r188 < r189 < r190 < r191 < r198 < r199 < r208 < r209 <
table 1 : data statistics comparison for the original e2e data and our cleaned version . < r > < c > [ bold ] dataset < c & c > < cap > [ cap > table 1 : number of distinct mrs , total number of textual references , ser as measured by our slot matching script , see section 3 ) . < r & c > : < c + c > original < e2e > train , test , dev , ser ( % ) < r + c : < c - c > e2ee > train test dev test < e > dev < e < c > ( 0 . 5pt / 2pt ] cleaned < c * train < e * train test < c * ) dev < c ) cleaned 0 . 00 % < r . 00 ) < r * < c . < e1 > [ e2ee ] cleaning 0 . 0 % < c1 . < c2e data statistics comparison for the original and cleaned e2es , see section 3 . [ r > > [ c + e ] original < c ] test < t > 4 , 862 < c > 42 , 061 < b > 17 . 69 < r / r > cleaned 1 . 00 ( 0pt / 0pt ) 0 . 42 < r # c > original < c : cleaned 2 . 00 ( 0 . 00 % ) 0 . 69 ( 0 % 0 . 42 ) 0 % 0 % 0 . 49 ( 0 % ) 0 . 69 ( 0 % 1 . 42 ) ( 0 . 49 ) 0 . 39 ( 0 ) 0 % 2 . 42 ( 0 % ) 2 . 49 < r % 2c . cleaned 3 . 00 . 0pt . 0pt / 1pt . 1pt / 3pt . < cap & c : 1 . 49 ( r + r > [ 0 . 05pt / 5pt ] 0 . 9pt / 4pt . [ 1 . 49 [ 0 . 9 . 0 ] ) 1 . 00pt / 9pt . 2pt / 10pt . 3pt / 11pt . 4pt / 12pt . 5pt / 13pt . 6pt / 14pt . 7pt / 15pt . 8pt / 16pt . 9pt / 17pt . 10pt / 18pt . 11pt / 20pt . 12pt / 21pt . 15pt / 22pt . 16pt / 23pt . 17pt / 24pt . 18pt / 25pt .
[ bold ] original < c > sc - lstm < c > 39 . 6704 < c + 36 . 11 < c > 5 . 75 < c % 1 . 53 < c & c > 0 . 06 < r > [ bold > [ c > test < c > . [ bold ] system < c . < r > . [ c ] [ bol ] [ cider ] < c ] train < c : [ r > < c } [ bid ] [ rid ] < bider < c > : [ bod ] [ todo ] [ did ] ( did ) < c ; [ bad ] [ ad ] < r > : [ r : [ dad ] ( ad ] ) < r : ( dad ) [ r ] : [ r ] [ rd : [ rd ] ( rd ] ) [ ddr ] ( dr ) [ rd : [ ddr ] [ ddr ] ] [ r ] [ dr ] [ dr ] [ dr ] [ dd ] ( dd ) [ ddr [ ddr ] , [ ddr | dd | dd ] ] [ rd ] [ dd ] [ dd | ddr ] , [ dmd ] [ dd : [ dmd | dd ] [ dmd ] , [ dmd [ dmd ] ] ] [ dd ] [ df ] [ dd ] ; [ ddd ] [ fd ] [ df ] ; [ dd ; fd ] [ df ; fd ; dmd ] [ fd ; fd ] ; fd ; fd : dmd ; ff ; ff : ddd ; fdd ; dfd ; dff ; ddf ; fdf ; ffd ; fff ; ff ) ; ff : ff ; fff ; ff , ff , fff , fff , ffd , ffff , fdf , ffnf , fffl , ffif , fifo , ffn , ffg , ffh , ffj , ffk , ffm , ffl , ffb , ffr , ffs , fft , ffu , ffv , ffq , ffw , ffy , ffi , ffp , ffx , ffz , ffxp , ffrg , ffrs , ffstm , fss , ffss , frs , fgs , fms , ffs , fas , fsm , fstm > 39 ffs . 80 < r . 27 < r00 . 2253 < c00 . 9355 < c > , 00 . 2681 < c < 00 . 77 < c02 00 . 01 < c # 01 . 04 < c / 01 .
table 4 : results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) . < r > < c > [ bold ] training data < c > . < c > " [ bol ] training error < c . < cap > table 3 : error analysis of the original tgen test set . < t > [ c > training error [ c ] [ bild ] training errors < t ] [ c + ] [ cap ] [ t ] error analysis error [ t ] + [ c ] + [ t + ] error analysis error error error [ b + ] error error error ( t + ) < tid > [ tid ] error data [ bid ] < c + [ cid ] [ ct ] < bid > error < c > ( tid ) < c < c > original < c > < c > 0 . 0 . 1 . 0 < / c > 22 < c > < / c > 14 < r . < bind ] add < / c >
< c > [ bold ] 28 . 1m < c > 29 . 4 < r > [ c > pbmt ( pourdamghani et al . , 2016 ) < c + - < b > 28 . 2m < c > 27 . 9 < r > < c > dcgcn ( ensemble ) < c < 0 . 0 < r > " < c > " graphlstm ( konstas and cohen , 2019 ) < b + < c > [ bold ] 27 . 1 < r > ) < c > . < r > . < c > < b > < c > < / b > dcnseq ( damonte and cohen , 2019 ) < b + < c > : 27 . 0m < m > 27m < b > . < b > < b > < r > . [ b ] < b < b > - < c . < r > , < b . < b < b > " < b " < b . " < b " ) < b < / b > b < b . < b > ( b ) < b ) < a > < a < b > , < a , < b , < a ) < a < b , < a , < b > , < a > < b < a > , < b < / a > , > < a < / b > , > > < ab < / a ) , < ab , < ab > < bb , < bb > , < bb > < cb , < bc , < cc , < ccc , < c , < d , < e , < f , < g , < h , < j , < k , < l , < m , < r , < s , < t , < u , < v , < w , < z , < x , < y , < p > < u > < v > , < v > < r > < t > < v > < z > < z > < t > < w > < w > < x > < y > < x > < y > < s > < u > < n > < s > > < d > < b > < c > , < c , < c ] < c : < b : < c ; < c > ) < b : < b ; < b > : < b ; < c | < b | < c / b < c * < b / c > seq2seqk ( konstas et al . , 2017 ) < f > - 20 . 2 < r : < r . 2 < r > : 0 . 2 < / r >
table 2 . table 2 : main results on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . # p shows the model size in terms of parameters ; “ s ” and “ e ” denote single and ensemble models , respectively . < r > < c > [ bold ] < cap > table 3 : results on gcn2seq ( beck et al . , 2018 ) and gcngcn ( beck and cohen , 2019 ) model sizes . < p > # p model < s > s < bold > 24 . 3m < c > 23 . 5m < m > [ mold ] 24 . 4 < m < c > e < e > 26 . 6m < c > , 26 . 4m < d > [ dold ] 26 . 5 < r > < c > dcgcn < e < e < e > 28 . 1 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 99 , 100 , 101 , 102 , 103 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 111 , 112 , 113 , 114 , 115 , 116 , 123 , 130 , 131 , 132 , 133 , 134 , 135 , 141 , 142 , 143 , 144 , 145 , 155 , 156 , 167 , 168 , 169 , 170 , 173 , 174 , 175 , 176 , 177 , 178 , 179 , 188 , 189 , 190 , 197 , 198 , 201 , 204 , 206 , 207 , 208 , 209 , 211 , 212 , 213 , 214 , 215 , 216 , 223 , 224 , 223
table 1 . < r > < c > [ bold ] model < c & c > < bold > [ c & d ] [ c + c ] [ b & c ] < b & d [ b + d ] < c + d > [ bc ] [ bcb ] [ ccb ] ( bold ) [ bcd ] ( bcd ) [ c ] ( ccb ) ( bcb ) [ bbd ] ( cbd ) ( cbc ) ( bold ) ( ccd ) ( cbc ) ( ccc ) ( cb ) ( tc ) ( ct ) ( t ) ( d ) ) ( c > ( c + ) ( c ) ( r ) ( g ) ( h ) ( j ) ( k ) ( l ) ( m ) ( n ) ( p ) ( q ) ( s ) ( z ) ( w ) ( x ) ( y ) ( a ) ( f ) ( u ) ( v ) ( e ) ( o ) ( i ) < c > " ( c " ) ( b - ) ( b + ) ( b ) ( c ) ( r ) ( b - ) ( b ) < c > ( c + ) ( c - ) ( c ) + ( c ) ( c ) < r > ( b + c ) < b > ( b + ) ( b ) + ( b + b ) < / b > ( r > < c > ) ( c - ) ( c ) ) ( b - c ) < / c > < b > [ b ] ( b - b ) [ b - a ] ( c - a ) ( d ) ( e ) ( f ) ( g ) ( h ) ( j ) ( k ) ( l ) ( m ) ( p ) ( s ) ( n ) ( t ) ( y ) ( x ) ( z ) ( w ) ( v ) ( u ) ( q ) ( a ( b ) ) ( c ) ) ( b ( r ) ) ( g ( b ) ( r ) ( c ) ( b ) ( b ) + ( r ( r ) ( r ) ) ( b ( b ) ) , ( r ( b ) , ( r ) , ( c ) , ( b , r ) ( b , b , c ) ( r , r , b ) ( c , c , d ) ) ( r < r > ) ( r > ( r , g , r ) < / r > ) ( r > ) < b . b . ( bastings et al . , 2017 ) < c . 2 < c > - < c > . 7 . 7 < c < 8 . 6 < c > ) 36 . 5 <
table 5 : the effect of the number of layers inside a block . < r > < c > [ italic ] [ bold ] [ c > b < c ] [ cap > [ c ] c < r > < c > 1 < c > . 1 < b > 1 < c > 17 . 3 < r < c > . 2 < c > , 1 < b > 18 . 1 < cap > table 4 : the effects of the size of the layers inside the block on the density of the block . [ r > n < c > < b > [ b > c > [ cap ] < r > . 2 < c > , 2 < b > . 1 < cap > < r > [ c > 2 < a > 2 < a > 3 < a > . 1 > < cap ] [ r > . 3 < b > , 3 < d > 4 < a > , 4 < b , 4 < c , 5 < a , 5 < / b , 6 < c ) < r > , 2 > c > 3 > b > c < r > 2 > a > b < r > , 3 > d > c < / r > n > b < / c > [ bold > 53 . 0 < c > 52 . 5 < cap > 48 . 4 < c + 49 . 7 < bold > 52 . 6 < ca > 51 . 3 [ c + ] 53 . 8 < bold . 2 < cap . 6 < c > ) 48 . 3 < r > . 4 > c . < b > [ c > c < r > [ b > b > [ cap ] 48 . 6 < / c > 49 . 4 < bold > < c > . 48 . 8 < / cap > 51 . < c > 48 . < b > ( c ) 53 . 2 < / b > 48 . 4 < / r > 50 . 7 < / cap ] 52 . 3 < / bold < r > ( c > 50 . < c > ) 50 . 0 < / cap > < r > 48 > 49 . 6 < / c > . 49 . 5 < / r > . 50 . 2 < / cap > 52 < / b > 50 < / c > : 50 . 4 < / cap < r > < b > , 5 < b > < c > , 6 < a > < / b > n > < b > < a > c > < c > < d > b > < r > ( b > b ) 52 . 8 < / b > < cap > 48 < / c > , 49 . 3 < / b > < / r > 50 . 7 < / cap ] 51 . 8 < b . 5 < / b > , 51 . 2 < cap . 6 < b < b > < / c > 52 . 3
< r > < c > [ bold ] gcn + rc + la ( 2 ) < b > b 16 . 9 < r > ( c > + rc ( 4 ) 18 . 1 < c > [ c > b 18 . 6 < rc + la ( 6 ) < c ] 18 . 7 < rc > [ cap > b 47 . 3 < r > . [ c ] c 47 . 4 < r . [ c + la ] c 48 . 0 < r > , [ bold ] 48 . 8 < cap > table 6 : comparisons with baselines . + rc denotes gcns with residual connections . gcn < bold > b 48 . 3 < c > 48 . 4 < r . < c > . [ bol ] c 49 . 1 < r > . [ c > c 50 . 0 < r > : [ c > . [ cap ] c 51 . 9 < cap > c 52 . 5 < r : [ cap ] dcgcn ( bold ) 50 . 1 > 50 . 2 < r + la . [ bal ] 50 . 3 [ r > c ] 51 . 0 [ r ] c 52 [ r ] : [ c ] . [ cap ] [ c ] 52 . 9 [ r : ] c 53 . 5 < r : [ cap | c ] [ cap | b ] 53 . 6 < cap | d ] [ c : ] [ b : c ] 54 . 5 [ r > [ r ] [ d ] : [ d : d ] 53 [ r ] [ d : c ] [ d ] [ c ] [ c | d ] [ d ] ] 53 . 8 [ r | d | d ] ] 54 . 8 [ r : d | c ; d ; c ; c ] ; c ; dcgcn1 ( 9 ) [ b > 22 . 8 < r ] + rc . [ dal ] 22 . 7 < r + ca . [ dc ] 24 . 7 [ r + c ] 25 . 2 [ r - c ] 26 . 4 [ r ] - r - d [ d - d ] dc gcn4 ( 36 ) < dal > 25 . 5 [ r = d + c . 5 ; r = r + d + d . 5 ] [ r = c . 4 ; d = d . 4 ] [ d = dc . 4 ] [ r + dc . 5 : d + r . 5 , d - r . 6 ; d - c . 6 : d - rc . 5 . d - l . 5 < / r > d - d . 6 . d . +
