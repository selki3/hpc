< extra_id_0 > training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s )
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . table 1 : throughput for the treernn model implemented with recursive dataflow graphs . table 1 : throughput for the treernn model implemented with recursive dataflow graphs .
< extra_id_0 > for each model with different representation . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations .
< extra_id_0 > [ bold ] relation c > [ bold ] relation c > [ bold ] relation c > [ bold ] relation c > [ bold ] relation c > [ bold ] relation c > [ bold ] relation c > [ bold ] relation c > [ bold ] relation c > [ bold ] relation c > [ bold ] relation c > [ bold ] relation c > [ bold ]
< extra_id_0 > 50 % c - f1 100 % c - f1 50 % c - f1 50 % c - f1 100 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1
< extra_id_0 > c > paragraph level c - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level f1 c >
< extra_id_0 > r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > test c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c
< extra_id_0 > r > c > [ bold ] dataset c > [ bold ] part c > [ bold ] refs c > [ bold ] ser ( % ) c > ( 0 . 00 ) r > c > [ 0 . 5pt / 2pt ] cleaned c > train c > 1 , 358 c > 4 , 693 c > ( 0 . 00 ) c > ( 0 . 00 ) c > ( 0 . 00 ) c >
< extra_id_0 > c > [ bold ] original c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c >
< extra_id_0 > table 4 : results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies , slight disfluencies ) .
< extra_id_0 > graphlstm ( song et al . , 2018 ) c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold
< extra_id_0 > achieves 24 . 5 bleu points . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . # p shows the model size in terms of parameters on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . # p shows the model size in terms of parameters on amr17 . ggnn2seq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . # p
< extra_id_0 > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] [ bold
< extra_id_0 > c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 2
< extra_id_0 > rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes
< extra_id_0 > c > 20 . 9m c > 20 . 9m c > 52 . 3m c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c >
< extra_id_0 > - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i -
< extra_id_0 > table 9 : ablation study for modules used in the graph encoder and the lstm decoder . c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty
< extra_id_0 > c > initialization c > depth c > objnum c > tense c > topconst c > glorot c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7
< extra_id_0 > c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst
< extra_id_0 > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c >
< extra_id_0 > c > sts12 c > sts13 c > sts14 c > sts15 c > sts16 r > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > sick - e c > sick - b c > sick - b c > sick - b c > sick - b c > sick - b c > sick - b c > sick - b c > sick - b c > sick - b c >
< extra_id_0 > c > sts12 c > sts13 c > sts14 c > sts15 c > sts16 r > c > cmow - c c > [ bold ] 43 . 5 c > [ bold ] 52 . 2 c > [ bold ] 43 . 5 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c >
< extra_id_0 > c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst
< extra_id_0 > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c >
< extra_id_0 > in [ italic ] e + loc c > all org c > all misc c > all loc c > all org c > all org c > all misc c > all org c > all org c > all misc c > all org c > all org c > all org c > all misc c > all org c > all
< extra_id_0 > ( model 1 ) c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c >
< extra_id_0 > / bold > ent / bold > c > ref gen / bold > neu / bold > c > ref gen / bold > neu / bold > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c >
< extra_id_0 > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold >
< extra_id_0 > 3 : results on ldc2015e86 test set when models are trained with additional gigaword data . konstas et al . ( 2017 ) c > 200k c > 27 . 40 r > c > song et al . ( 2018 ) c > 200k c > 31 . 60 r > .
< extra_id_0 > c > bold > bleu / bold > c > bold > bleu / bold > c > bold > bleu / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > 0 - 7
< extra_id_0 > bold > model / bold > bold > miss / bold > bold > added / bold > bold > miss / bold > bold > added / bold > bold > miss / bold > bold > added / bold > bold > miss / bold > bold > added / bold > bold >
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) .
< extra_id_0 > r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c >
< extra_id_0 > 5 : pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . table 5 : pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual encoders .
< extra_id_0 > c > task c > task c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c >
< extra_id_0 > r > c > task c > accuracy r > c > sentiment c > 67 . 4 r > [ italic ] gender c > 67 . 4 r > [ empty ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c >
< extra_id_0 > r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > table 3 : performances on different datasets with an adversarial training . is the difference between the attacker score and the adversarial accuracy . is the difference between the attacker score and the adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy .
< extra_id_0 > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty
< extra_id_0 > model c > wt2 + finetune c > wt2 + dynamic c > wt2 + finetune c > wt2 + finetune c > wt2 + finetune c > wt2 + finetune c > wt2 + finetune c > wt2 + finetune c > wt2 + finetune c > wt2 + finet
< extra_id_0 > c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c
< extra_id_0 > c > yelppolar err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c >
< extra_id_0 > c > train c > decode c > train c > train c > train c > decode c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > decode
< extra_id_0 > “ # params ” : the parameter number of base . “ # params ” : the parameter number of elmo . rnet * : results published by wang et al . ( 2017 ) .
< extra_id_0 > “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task .
< extra_id_0 > 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting . table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting .
< extra_id_0 > retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # word c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # word c > [ italic ] c
< extra_id_0 > the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold .
< extra_id_0 > dsim c > corpus c > docsub c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c >
< extra_id_0 > c > dsim c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > dsim c > dsim c > dsim c > dsim c > dsim c > dsim c > dsim c > dsim c > dsim c > dsim
< extra_id_0 > dsim c > corpus c > docsub c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c >
< extra_id_0 > 957 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c >
< extra_id_0 > 980 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c > 1000 c >
< extra_id_0 > lf is the enhanced version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned in table 1 .
< extra_id_0 > c > lf c > hciae c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c
< extra_id_0 > c > cs - en c > fi - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > c >
< extra_id_0 > / bold > zh - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > average c >
< extra_id_0 > > qual / bold > bold > inf / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual
< extra_id_0 > m1 m2 r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > c > 63 . 2 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8
< extra_id_0 > b > a c > fluency tie c > fluency tie c > fluency tie c > fluency tie c > fluency tie c > fluency tie c > fluency tie c > fluency tie c > fluency tie c > fluency tie c > fluency tie c > fluency tie c > fluency tie c > fluency
acc c > % of machine and human judgments that match c > 94 c > 84 r > c > acc c > % of machine and human judgments that match c > 0 . 79 c > 0 . 75 c > 0 . 67 c > spearman ’ s [ italic ] b / w negative pp and human ratings of fluency c > 0 . 81 c > 0 . 67 c >
< extra_id_0 > 0 . 818 c > 27 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 3 c > 21 . 6
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than prior work at similar levels of acc , but untransferred sentences achieve the highest bleu than prior work at similar levels of bleu . bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than prior work at similar levels of acc .
< extra_id_0 > table 2 : percent of reparandum tokens that were correctly predicted as disfluent . * statistics exclude repetition tokens for nested disfluencies .
< extra_id_0 > c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c >
< extra_id_0 > c > [ bold ] test mean c > [ bold ] test mean c > [ bold ] test best c > [ bold ] test mean c > [ bold ] test mean c > [ bold ] test mean c > [ bold ] test mean c > [ bold ] test mean c > [ bold ] test mean c > [ bold ] test mean c > [ italic ] c >
< extra_id_0 > ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > average of word2vec embedding c > 12 . 43 c > 01 . 30 c > 53 . 24 c > 79 . 53 c > 81 . 72 c > [ bold ] 83 . 54 c > [ bold ] 83 . 54 c > [ bold ]
< extra_id_0 > r > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > table 3 : accuracy ( % ) comparisons of component models with and without attention . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > [ bold ] 1 / 1 c > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] all r > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c >
< extra_id_0 > ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ]
< extra_id_0 > perp
< extra_id_0 > c > 25 % train dev c > 50 % train dev c > 50 % train test c > 75 % train dev c > 75 % train test c > cs - only c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c >
cap > table 5 : accuracy on the dev set and on the test set according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) .
< extra_id_0 > table 5 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) . cap > table 5 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) .
< extra_id_0 > hpcd ( full ) is from the original paper , and it uses syntactic skipgram . glove - retro uses glove vectors retrofitted by faruqui et al . ( 2015 ) to wordnet 3 . 1 , and glove - extended uses glove vectors .
< extra_id_0 > c > [ bold ] full uas c > [ bold ] full uas c > [ bold ] full uas c > [ bold ] full uas c > [ bold ] full uas c > [ bold ] full uas c > [ bold ] full uas c > [ bold ] full uas c > [ bold ] full uas c > [ bold ] c > [ bold
< extra_id_0 > r > c > [ bold ] model c > [ bold ] ppa acc . r > c > full c > 89 . 7 r > c > - sense priors c > 88 . 4 c > - attention c > 87 . 5 cap > table 3 : effect of removing sense priors and context sensitivity from the model .
< extra_id_0 > r > c > en - de c > flickr16 c > flickr17 c > mscoco17 r > c > multi30k c > 61 . 4 c > 54 . 0 c > 43 . 1 c > c > + ensemble - of - 3 c > [ bold ] 43 . 9 c > [ bold ] 37 . 0 c > [ bold ] 37 . 0 c > [ bold
< extra_id_0 > mscoco17 c > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c >
< extra_id_0 > table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : adding automatic image
< extra_id_0 > c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco
< extra_id_0 > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c >
< extra_id_0 > en - fr - trans - ff c > 0 . 7107 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c > 0 . 9925 c >
< extra_id_0 > table 1 : number of parallel sentences in the train , test and development splits for the language pairs we used . table 1 : number of parallel sentences in the train , test and development splits for the language pairs we used . table 1 : number of parallel sentences in the train , test and development splits .
< extra_id_0 > 2 : training vocabularies for the english , french and spanish data used for our models . table 2 : training vocabularies for the english , french and spanish data used for our models .
< extra_id_0 > r > c > system reference c > en - fr - rnn - rev c > 33 . 3 c > 50 . 2 r > c > en - fr - trans - rev c > 36 . 5 c > 47 . 1 r > c > en - fr - trans - rev c > [ bold ] 40 . 4 c > [ bold ] 42 . 7 c > [ bold
< extra_id_0 > r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > she turns in a u > screenplay screenplay that u > at the edges ; it ’ s so clever you want hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate
< extra_id_0 > bold > 53 / bold > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > rnp / bold > rnp / bold > rnp / bold > r > r >
< extra_id_0 > bold > rnn / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold
< extra_id_0 > objective c > bold > pubmed / bold > positive c > bold > sst - 2 / bold > negative c > bold > pubmed / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
