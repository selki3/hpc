< extra_id_0 > table 2 shows the throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . the recursive approach performs the best on inference with efficient parallel execution of tree nodes , while the folding technique shows better performance on training thanks to its gpu exploitation .
< extra_id_0 > table 1 shows throughput for the treernn model implemented with recursive dataflow graphs . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 . the balanced dataset exhibits the highest throughput thanks to the high degree of parallelization .
< extra_id_0 > activation func . c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters l2 reg . c > [ bold ] conll08 c > c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold ] c > [ b
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) without sdp and [ bold ] best f1 ( in 5 - fold ) with sdp . using the shortest dependency path on each relation type is shown in table 1 . using the shortest dependency path is shown in table 1 .
< extra_id_0 > c - f1 100 % c > r - f1 50 % c > r - f1 100 % c > r - f1 50 % c > r - f1 50 % c > r - f1 50 % c > r - f1 100 % c > f1 50 % c > y - 3 : yitalic > c / italic > - 1 c > 67 . 69 c > 67 . 69 c > 67 . 69 c >
< extra_id_0 > r - f1 and r - f1 , respectively , and essay level f1 and r - f1 respectively . the results show that mst - parser performs better than [ empty ] and [ empty ] with respect to all the parameters . the results show that mst - parser performs better than [ empty ] and [ empty ] compared to [ empty ] and [ empty ] with respect to all the parameters .
< extra_id_0 > c > [ empty ] c > lstm - parser c > [ empty ] c > paragraph vs . essay vs . lstm - parser c > c - f1 ( 100 % ) in % for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the runs given in table 2 . note that the mean performance is lower than the majority performance over the runs given
< extra_id_0 > nist c > bleu c > [ bold ] nist c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ser c > [ bleu ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser
< extra_id_0 > table 1 : data statistics comparison for the original e2e data and our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by our slot matching script , see section 3 ) . the original e2e data contains 4 , 862 distinct mrs , 42 , 061 textual references and ser ( % ) .
< extra_id_0 > nist c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ser c > [ bleu c > [ bleu ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser
< extra_id_0 > table 4 shows the results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) . the total absolute numbers of errors we found are shown in table 4 .
< extra_id_0 > graphlstm ( song et al . , 2018 ) and snrg ( song et al . , 2018 ) have significantly higher bold scores than snrg ( song et al . , 2017 ) and gcnseq ( damonte and cohen , 2019 ) have significantly higher bold scores than snrg ( song et al . , 2018 ) and gcnseq ( damonte and cohen , 2019 ) have significantly higher bold scores than snrg ( song et al . , 2018 ) have a significantly higher all score of 24 . 4 respectively . graphlseq ( damonte and cohen , 2019 ) have a higher all score of 24 . 4 respectively .
< extra_id_0 > the model size in terms of parameters . gcnseq achieves 24 . 5 bleu points on amr17 . ggnn2seq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . ggnn2seq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 .
< extra_id_0 > english - czech b c > [ bold ] english - german # p c > [ bold ] english - czech b c > [ bold ] english - german # p c > [ bold ] english - czech b c > [ bold ] english - german b c > [ bold ] english - german b c > [ bold ] english - german b c > [ bold ] english - german b c > czech b c > [ bow + gcn ( bastings et al . , 2017 ] [ beck et al . , 2017 ] english - german p c > [ beck et al . , 2017 ] english - german p c > [ beck et al . , 2017 ] english - german c c > [ beck et al . , 2017 ] english - german p c > [ beck et al . , 2017 ] c > [ beck et al . , 2017 ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > c > 1 c > 2 c > 50 . 3 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + la denotes + rc denotes + rc denotes + rc denotes + rc denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc denotes gcn + rc de
< extra_id_0 > d c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > dcgcn ( 1 ) c >
< extra_id_0 > table 8 shows the ablation study for density of connections on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > table 9 : ablation study for modules used in the graph encoder and the lstm decoder . using the dcgcn4 encoder and the lstm decoder , the lstm encoder performs better than the encoder and the lstm decoder in terms of coverage mechanism .
< extra_id_0 > initialization c > depth c > objnum c > length c > coordinv c > glorot c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > method c > depth c > tense c > objnum c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > mpqa c > mpqa c > mpqa c > mrpc c > sick - e c > sick - r c > hybrid c > sick - r c > sick - r c > sick - r c > sick - r c > sick - r c > sick - r c > sick - r c > sick - r c > sick - r c > sick - r c > sick - r c > sick - r c > sick - e c > sick - r c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > sts15 and sts16 are compared to cbow and cmow , respectively . hybrid and cmow achieve higher scores on unsupervised downstream tasks than hybrid and cmow .
< extra_id_0 > mrpc , mpqa , mpqa , mpqa and mrpc . our paper outperforms glorot and glorot in the initialization and subj datasets . glorot outperforms glorot and glorot in the sick - e and sick - b datasets , respectively .
< extra_id_0 > c > sts15 c > sts16 c > cmow - c c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ cbow - r c > [ cbow - r c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ cbow - r c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ cbow - r c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold
< extra_id_0 > topconst c > wc c > wc c > wc c > cmow - c c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > cmow - c c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > mpqa c > mpqa c > mpqa c > mrpc c > sick - e c > sick - r c > cmow - c c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > mrpc c > cmow - c c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ]
< extra_id_0 > all org c > all misc c > all misc c > all loc c > all org c > all misc c > all misc c > all misc c > all loc c > all org c > all misc c > all misc c > all loc c > all org per c > all misc c > all misc c >
< extra_id_0 > all p c > all r c > all f1 c > all p c > all p c > all f1 c > all p c > all p c > all f1 c > all p c > all p c > all f1 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c >
< extra_id_0 > gen ref gen bold > ent / bold > gen ref gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin
< extra_id_0 > > bold > bleu / bold > bold > meteor / bold > bold > bleu / bold > bold > g2s - gin c > 22 . 55 0 . 17 0 . 16 0 . 16 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 .
< extra_id_0 > table 3 shows the results on the ldc2015e86 test set when models are trained with additional gigaword data . c > konstas et al . ( 2017 ) showed that models trained with additional bleu data perform better than those trained with g2s - ggnn .
< extra_id_0 > bold > meteor / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > 0 - 7
< extra_id_0 > table 8 shows the fraction of elements in the output that are not present in the input ( added ) and the fraction of elements in the input that are missing in the generated sentence ( miss ) , for the test set of ldc2017t10 . the token lemmas are used in the comparison .
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer .
< extra_id_0 > table 2 shows mft and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound are shown in table 2 .
< extra_id_0 > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c >
< extra_id_0 > table 5 shows pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual encoders are shown in table 5 .
< extra_id_0 > task c > sentiment c > sentiment c > sentiment c > mention c > sentiment c > sentiment c > mention c > gender c > 9 . 7 on a training set 10 % held - out , the attacker ’ s performance on different datasets is shown in table 8 . the difference between the attacker ’ s score and the adversary ’ s accuracy is shown in table 8 .
< extra_id_0 > c > task c > accuracy c > sentiment c > 67 . 4 r > c > [ empty ] c > mention c > 67 . 4 r > c > [ italic ] c > [ empty ] c > [ italic ] c > [ captcha ] c > [ captcha ] c > accuracies when training directly towards a single task .
< extra_id_0 > table 2 : protected attribute leakage : balanced & unbalanced data splits . mention c > 67 . 4 c > 64 . 5 c > 79 . 5 c > 73 . 5 c > unbalanced leakage c > 73 . 8 c > 59 . 7 c > 59 . 7 c > 59 . 7 c > 59 . 7 c > 59 . 7 c > c >
< extra_id_0 > data c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > mention c > gender c > mention c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > embedding guarded and leaky with different encoders . table 6 shows the accuracies of the protected attribute with different encoders . leaky achieves 64 . 5 compared to 67 . 8 for rnn and 54 . 8 for rnn .
< extra_id_0 > wt2 + finetune c > wt2 + dynamic c > ptb + finetune c > ptb + finetune c > wt2 + dynamic c > yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared to yang et al . ( 2018 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 )
< extra_id_0 > base acc c > + bert acc c > + bert time c > + ln acc c > + bert time c > + ln time c > + bert time c > + ln time c > + bert time c > + ln time c > + ln time c > + bert time c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > yahoo err c > yahoo time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > lstm c > 227k c >
< extra_id_0 > bleu score on wmt14 english - german translation task . train and decode : time in seconds measured from 0 . 2k training steps on tesla p100 . train and decode : time in milliseconds used to decode one sentence on newstest2014 dataset .
< extra_id_0 > table 4 : exact match / f1 - score on squad dataset . “ # params ” : the parameter number of base . “ rnet ” : the results published by wang et al . ( 2017 ) .
< extra_id_0 > table 6 shows the f1 score on conll - 2003 english ner task . lstm * denotes the f1 score on conll - 2003 english ner task . lstm * denotes the parameter number .
< extra_id_0 > table 7 : test accuracy on snli and ptb task with base + ln setting and test perplexity on snli and ptb task with base + ln setting . elrn outperforms glrn and glrn in accuracy and perplexity . elrn outperforms glrn in accuracy and perplexity .
< extra_id_0 > b - 2 and r - 2 , respectively , compared to [ italic ] w / system retrieval [ bold ] and [ italic ] w / system retrieval [ bold ] and [ italic ] w / system retrieval [ bold ] and [ sent ] c > [ italic ] w / system retrieval [ bold ] mtr c > [ italic ] w / system retrieval [ bold ] mtr c > [ italic ] compared to [ italic and [ italic ] w / system retrieval [ bold ] mtr c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ italic ] w / system retrieval [ bold ] mtr c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] w / system retrieval [ bold [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] w / system retrieval [ bold [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > top - 1 / 2 : % of evaluations a system being ranked as a best . top - 1 / 2 : % of evaluations a system being ranked as a best . human evaluation on grammaticality , appropriateness ( appr ) , and content richness ( cont . ) is highlighted in bold , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is 1 . 0 . seq2seq performs better than seq2
< extra_id_0 > 0761 . df c > df c > docsub c > hclust c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > hclust c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > slqs and docsub . hclust outperforms the lang c > corpus c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > cluster cluster cluster cluster cluster cluster clust cluster clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust c
< extra_id_0 > 0761 and tf c > 0 . 1038 compared to df c > 0 . 0461 and tf c > 0 . 0661 respectively . moreover , pt c > hclust and df c > europarl achieve significantly higher p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c >
< extra_id_0 > slqs , docsub and hclust . all corpus based on df and docsub are based on df and docsub . europarl has the highest avgdepth and maxdepth , respectively . europarl has the lowest avgdepth and maxdepth , respectively . europarl has the lowest avgdepth and maxdepth .
< extra_id_0 > slqs , docsub and hclust . all corpus models have the same avgdepth as all corpus models except for docsub and docsub . all corpus models have the same avgdepth as all corpus models except for docsub and docsub . all corpus models have the same avgdepth as all corpus models except for europarl . europarl has the highest avgdepth of all corpus models except for docsub .
< extra_id_0 > table 1 shows the performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as mentioned in table 1 . qt , s and d denote question type , answer score sampling , and hidden dictionary learning , respectively . r0 , r2 , r3 denote regressive loss , weighted softmax loss , binary sigmoid loss , and generalized ranking loss .
< extra_id_0 > table 2 shows the performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . using coatt and coatt , we can see that p2 is the most effective one ( i . e . hidden dictionary learning ) shown in table 1 .
< extra_id_0 > fi - en c > lv - en c > cs - en c > cs - en c > lv - en c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > cs - en and de - en c > bold > direct assessment / bold > zh - en c > bertscore - f1 c > 0 . 672 c > 0 . 646 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > 0 . 672 c > 0 . 672 c > 0 . 672 c > c > c > bertscore - f1 c > bertscore - f1 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 ruse ( * ) bertscore - f1 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 ruse ( * ) bertscore - f1 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c > 0 . 686 c >
< extra_id_0 > nat / bold > c > sfhotel bold > qual / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > m1 and m2 respectively , and leic ( * ) c > 0 . 949 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > 0 . 750 c > c > c > bertscore - recall c >
< extra_id_0 > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m1 : m0 [ italic ] + cyc c > m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m0 : m4 : m0 : m4 : m0 : m4 : m4 : m0 : m4 : m0 : m4 : m0 : cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + para
< extra_id_0 > transfer quality a > b and transfer quality tie c > semantic preservation b > a and semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim
< extra_id_0 > c > metric ; yelp c > lit . c > human sentence - level validation of metrics ; 100 examples for each dataset for validating acc ; 150 for sim and 150 for pp ; see text for validation of gm ; see text for validation of acc ; see text for validation of acc .
< extra_id_0 > gm and sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m1 : m0 [ italic ] + cyc + para c > m6 : m6 : m3 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m0 [ italic ] + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc + para + cyc
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work , but untransferred sentences achieve the highest bleu than prior work at similar levels of acc . our best models achieve higher bleu than previous work , but untransferred sentences achieve the highest bleu than prior work at similar levels .
< extra_id_0 > reparandum length [ bold ] 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 3 - 5 , rephrase 1 - 2 , rephrase 1 - 2 , rephrase 1 - 2 , rephrase 1 - 2 , rephrase 3 - 5 , rephrase 3 - 5 , restart 3 - 5 , rephrase 3 - 5 , et al . ( 2017 ) , et al . ( 2017 ) , et al . ( 2017 ) , et al . ( 2017 ) , et al . ( 2017 ) , et al . ( 2017 ) , et al . ( 2016 ) .
< extra_id_0 > reparandum length [ bold ] 3 - 5 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both the reparandum and repair ( content - content ) , either the reparandum or repair ( content - function ) or in neither . the proportion of tokens belong to each category is shown in table 3 .
< extra_id_0 > [ bold ] test mean c > [ bold ] dev best c > [ bold ] dev mean c > [ bold ] dev best c > [ bold ] dev mean c > [ bold ] dev best c > [ bold ] dev mean c > [ bold ] dev best c > [ empty ] c > early c > text + raw + innovations c > 86 . 54 c > 86 . 54 c > [ empty ] – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – –
< extra_id_0 > accuracy ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > performance comparison with the state - of - art algorithms on the fnc - 1 test dataset . our model achieves a better performance than the state - of - art ones .
< extra_id_0 > table 2 : accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models in accuracy ( higher is better ) .
< extra_id_0 > table 3 shows the accuracy ( % ) comparisons of component models with and without attention . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > model c > [ bold ] 1 / 1 c > [ bold ] 1 / n all c > [ bold ] all c > [ bold ] embedding + t c > 75 . 3 c > 69 . 8 c > embedding + t c > 75 . 3 c > 69 . 8 c > 69 . 8 c > embedding + t c > 69 . 8 c > c >
< extra_id_0 > classification ( % ) c > trigger [ bold ] identification ( % ) c > trigger [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] c > [ bold ] identification ( % ) c > [ bold ) c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold ] c >
< extra_id_0 > wer c > dev perp c > test perp c > test wer c > test perp c > test wer c > test perp c > test perp c > test perp c > test wer c > spanish - only - lm c > 329 . 68 c > spanish - only - lm c > all : shuffled -
< extra_id_0 > train test and full train test set using discriminative training with only subsets of the code - switched data . table 4 summarizes the results on the dev set and on the test set using discriminative training with only subsets of the code - switched data . the results on the dev set and on the test set are shown in table 4 .
< extra_id_0 > table 5 summarizes the results on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) . cs and fine - tuned - disc achieve better accuracy on the dev set and on the test set .
< extra_id_0 > table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset are shown in table 7 .
< extra_id_0 > c > [ bold ] p , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) . using type - aggregated gaze features on the conll - 2003 dataset improves precision , recall and recall scores .
< extra_id_0 > table 1 shows the results on belinkov2014exploring ’ s ppa test set . lstm - pp and glove embeddings achieve 88 . 7 on the wordnet and verbnet test sets . ontolstm - pp and glove - extended embeddings achieve 84 . 8 on the wordnet and verbnet test sets .
< extra_id_0 > table 2 summarizes results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachments . the results are presented in table 2 . the rbg dependency parser with features coming from various pp attachment predictors and oracle attachments .
< extra_id_0 > table 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the model . the effect of removing sense priors and context sensitivity ( attention ) from the model is shown in table 3 .
< extra_id_0 > adding subtitle data and domain tuning for image caption translation ( bleu % scores ) . all results with marian amun are shown in table 2 . add subtitle data and domain tuning for multi30k and mscoco .
< extra_id_0 > , mscoco17 and en - de c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > en - de c > flickr16 c > flickr17 c > mscoco17 c > c > c > c > c > c > c > c > c > c > c > c > en - de c > mscoco17 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > mscoco17 c > mscoco17 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > mscoco17 c > mscoco17 c > mscoco17 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > mscoco17 c > mscoco17 c > mscoco17
< extra_id_0 > mscoco17 and en - de c > flickr16 c > flickr17 c > mscoco17 c > en - fr c > multi30k c > 61 . 4 c > + autocap 1 - 5 ( concat ) c > 32 . 0 c > 27 . 0 c > + autocap 1 - 5 ( concat ) c > 32 . 2 c > + autocap 1 - 5 ( concat ) c >
< extra_id_0 > and mscoco17 . we observe that enc - gate and dec - gate perform better than enc - gate and enc - gate , respectively . we observe that enc - gate and dec - gate perform better than enc - gate and enc - gate , respectively . we observe that enc - gate and dec - gate perform better than enc - gate and enc - gate , respectively .
< extra_id_0 > and mscoco17 . the subs3m and subs6m lm detectron perform better than en - fr and en - fr en - fr and mscoco17 . the subs3m and subs6m lm detectron perform better than en - fr and mscoco17 . the subs3m and subs6m lm detectron perform better than en - fr and mscoco17 .
< extra_id_0 > < extra_id_1 > > yule ’ s i c > ttr c > mtld c > mtld c > en - fr - trans - ff c > 9 . 2793 c > en - fr - trans - ff c > 1 . 0925 c > 121 . 5801 c > en - fr - trans - back c > 9 . 2793 c > en - fr - trans - ff c >
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . en – es has 1 , 472 , 203 parallel sentences in the train , test and development splits and en – es has 4 , 99 , 487 parallel sentences .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . the src and trg training vocabularies for the english , french and spanish datasets are shown in table 2 .
< extra_id_0 > table 5 summarizes the automatic evaluation scores ( bleu and ter ) for the rev systems ( en - fr - rnn - rev and en - fr - smt - rev ) .
< extra_id_0 > recall @ 10 ( % ) and median rank on flickr8k . the row labeled vgs is the visually supervised model from chrupala2017representations . the mean mfcc is 0 and the mean mfcc is 0 . 0 .
< extra_id_0 > table 1 summarizes the results on synthetically spoken coco . recall @ 10 ( % ) is significantly higher than rsaimage and mfcc , respectively . rsaimage has a higher recall rate than rsaimage and a higher recall rate than rsaimage . rsaimage has a higher recall rate than rsaimage and a higher recall rate than rsaimage .
< extra_id_0 > she turns in a u > screenplay that u > at the edges edges edges curves so clever you want hate hate hate hate hate hate hate . we report further examples in the appendix .
< extra_id_0 > bold > rnn , bold > dan , bold > dan , bold > dan , bold > dan , bold > dan , bold > dan , bold > dan , bold > dan , bold > dan , bold > dan , bold > dan , bold > dan , bold > dan , cnn , ( cnn , / bold > dan , / bold > dan , / bold > ) , / bold > , / bold > , / bold > , / bold > , / bold > . / bold > , / bold > , / bold > , / bold > , / adj . / adj . / adj . / adj . / adj . / adj .
< extra_id_0 > the numbers indicate the changes in percentage points with respect to the original sentence . the last two rows correspond to the case where negative labels are flipped to positive and vice versa . the changes in sentiment indicate that the score increases in positive and negative sentiment .
< extra_id_0 > n ’ t c > evaluate c > conclusions r > bold > pmi / bold > bold > pmi / bold > bold > pmi / bold > bold > pmi / bold > bold > pmi / bold > c > love c > bad c > n ’ t c > evaluate c > conclude r > c >
