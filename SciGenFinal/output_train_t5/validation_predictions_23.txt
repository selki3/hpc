< extra_id_0 > training c > throughput ( instances / s ) inference c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . the recursive framework performs
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization .
< extra_id_0 > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] with default values with optimal values with default values with optimal values with optimal values with optimal values with default values with optimal values with optimal values with optimal values with default values with optimal values with optimal values with optimal values with default values with optimal values with optimal values with default values with optimal values with optimal values with default values with optimal values with optimal values with default values with optimal values with optimal values with default values with optimal values with optimal values with default values with optimal values with default values with optimal values with default values with optimal values with default values with optimal values with default values with optimal values with optimal values with default values with optimal values with default values with optimal values with default values with optimal values with optimal values with default values with optimal values with default values with optimal values with default values with optimal values with optimal values with default values with optimal values with optimal values with default values with optimal values with optimal values with default values with optimal values with optimal values with default values with optimal values with default values with optimal values with default values with optimal values with optimal values with default values with optimal values with optimal values .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) with sdp [ bold ] best f1 ( in 5 - fold ) without sdp [ bold ] best f1 ( in 5 - fold ) without sdp [ bold ] best f1 ( in 5 - fold ) without sdp [ bold ] best f1 ( in 5 - fold ) without sdp [ bold ] with sdp [ bold ] [ bold ] [ bold ] with sdp [ bold without sdp [ bold without sdp [ bold without sdp [ bold without sdp [ bold ] without sdp [ bold without sdp [ bold without sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold [ bold ] with sdp [ bold [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold [ bold ] with sdp [ bold ] with sdp [ bold [ bold ] with sdp [ bold ] [ bold ] [ bold ] [ bold ] [ bold [ bold ] [ bold ] [ bold ]
< extra_id_0 > > f1 100 % c - f1 100 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c > y - 3 significantly outperforms c >
< extra_id_0 > and paragraph level acc . c > paragraph level acc . c > paragraph level c - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c >
< extra_id_0 > c > [ empty ] c > lstm - parser c > [ empty ] c > lstm - parser c > [ empty ] c > [ empty ] c > [ empty ] c > [ parser ] c > 100 % in c - f1 ( 100 % ) for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the
< extra_id_0 > train c > test c > train c > train c > test c > train c > train c > test c > train c > train c > train c > test c > train c > train c > train c > test c > train c > train c > test c > train c > train c > test c > train c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select
< extra_id_0 > c > [ bold ] mrs c > [ bold ] refs c > [ bold ] ser ( % ) c > 11 . 49 for the original e2e data and our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by slot matching script , see section 3 ) .
< extra_id_0 > nist c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu c > [ bleu c > [ bleu c > [ bleu c > [ bleu c > [ bleu ] c > [ bleu c > [ bleu ] c > [ bleu c > [ bleu ] c > [ bleu c > [ bleu c > [ bleu ] c > [ bleu c > [ bleu c > [ bleu c > [ bleu c > [ bleu c > [ bleu c > [ bleu c > [ bleu c > [ bleu c > [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ cider [ bold ] [ bold ] [ bold ] [ cider [ bold ] [ bold ] [ cider [ bold ] [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ bold ] [ cider [ b
< extra_id_0 > table 4 : results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies , slight disfluencies ) .
< extra_id_0 > graphlstm ( song et al . , 2018 ) and snrg ( song et al . , 2018 ) have the best performance . snrg has the best performance at 22 . 8m , whereas gcnseq has the best performance at 24 . 4m . graphlstm has the best performance at 24 . 4m , whereas snrg has the best performance at 25 . 6m . snrg and gcnseq have the best performance at 24 . 4m .
< extra_id_0 > gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . ggnn2seq achieves 24 . 5 bleu points on amr17 . ggnn2seq achieves 24 . 5 bleu points on amr17 . ggnn2seq achieves 24 . 5 bleu points on amr17 .
< extra_id_0 > german b c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german b c > [ bold ] english - german b c > [ bold ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + la denotes + rc .
< extra_id_0 > d c > b c > c c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d c > d >
< extra_id_0 > table 8 shows the ablation study for density of connections on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > table 9 : ablation study for modules used in the graph encoder and the lstm decoder . the lstm encoder and the dcgcn4 encoder have significantly better performance than the encoder and lstm decoder .
< extra_id_0 > initialization c > depth c > objnum c > length c > coordinv c > glorot c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > subjnum c > tense c > objnum c > topconst c > topconst c > topconst c > topconst c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > mpqa c > mpqa c > mpqa c > mrpc c > sick - e c > sick - r c > sick - r c > sick - r c > sick - r c > sick - r c > 79 . 2 c > 79 . 6 c > 79 . 6 c > 79 . 6 c > 79 . 6 c > sick - r
< extra_id_0 > c > sts14 c > sts15 c > sts16 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > cmp .
< extra_id_0 > mrpc and mpqa . mrpc and mpqa perform better than sick - e and sick - r . mrpc and mrpc perform better than glorot and sick - r and sick - r , respectively .
< extra_id_0 > c > sts14 c > sts15 c > sts16 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > tense and coordinv c > objnum c > topconst c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > cmow - c c > cmow - c c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > cmow - c c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > cmow - c c > wc c > wc c > wc
< extra_id_0 > mpqa c > mrpc c > sick - e c > sick - b c > sick - r c > sick - e c > sick - e c > sick - r c > sick - e c > sick - r c > sick - r c > sick - r c > sick - e c > sick - r c > sick - r c > sick - r c > sick - r c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > all org c > all misc c > all loc c > all org c > all misc c > all misc c > all loc c > all org c > all per c > all misc c > mil - nd c > 57 . 15 c > 89 . 46 c > 89 . 46 c > 89 . 46 c > 89 . 46 c >
< extra_id_0 > all p c > all r c > all f1 c > in [ italic ] e + p c > in [ italic ] e + r c > in [ italic ] e + f1 c > all p c > in [ italic ] e + p c > in [ italic ] e + r c > all f1 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > in [ italic ] c > in [ italic ] c > in [ italic ] c > in [ italic ] c > in [ italic ] c > in [ italic ] c > in [ italic ] c > in [ italic ] c > in [ italic ] c > in [ bold ] c > in [ bold in [ bold in [ bold in [ bold in [ bold in [ italic ] c > in [ italic ] c > in [ italic ] c > in [ italic ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > gen ref gen con / bold > con / bold > con / bold > con / bold > con / bold > con / bold > con / bold > con / bold > con / bold > con / bold > con / bold > con / bold > con / bold > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content > content >
< extra_id_0 > > bold > meteor / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > bold > model / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > /
< extra_id_0 > bold > meteor / bold > bold > size / bold > c > 57 . 6m c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > 0 - 7
< extra_id_0 > table 8 shows the fraction of elements in the output that are missing in the generated sentence ( added ) and the fraction of elements in the input that are missing in the generated sentence ( miss ) for the test set of ldc2017t10 . the token lemmas are used in the comparison .
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . table 4 : sem and pos tagging accuracy using features extracted from the nmt encoding layer .
< extra_id_0 > table 2 shows the pos and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound is shown in table 2 .
< extra_id_0 > fr c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c
< extra_id_0 > table 5 shows pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual encoders are shown in table 5 .
< extra_id_0 > task c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > mention c > gender c > men
< extra_id_0 > task c > accuracy c > 67 . 4 r > c > [ empty ] c > [ italic ] gender c > 67 . 4 r > c > [ empty ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > accuracies when training directly towards a single task c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > table 2 : protected attribute leakage : balanced & unbalanced data splits . mention c > 67 . 4 c > 64 . 5 c > 73 . 5 c > 73 . 5 c > 73 . 8 c > 59 . 7 c > 59 . 7 c > 59 . 7 c > 59 . 7 c > 59 . 7 c > 59 . 7 c > 59 . 7 c >
< extra_id_0 > data c > task acc c > leakage c > 5 . 0 on different datasets with an adversarial training . is the difference between the attacker score and the corresponding adversary ’ s accuracy .
< extra_id_0 > c > [ empty ] c > [ empty ] c > [ empty ] c > embedding leaky c > 67 . 8 c > accuracies of the protected attribute with different encoders in table 6 .
< extra_id_0 > ptb + finetune c > ptb + dynamic c > wt2 base c > wt2 + finetune c > wt2 + dynamic c > yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared to yang et al . ( 2018 ) c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm
< extra_id_0 > + bert acc c > + ln acc c > + bert time c > + ln time c > + bert time c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > amapolar time c > yahoo err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > zhang et al . ( 2015 ) c >
< extra_id_0 > model c > # params c > train c > decode c > train c > train c > train c > decode c > train c > train c > decode c > train c > decode c > decode c > decode c > decode c > decode c > decode c > decode c > decode c > train c > train c > decode bleu c > decode bleu c > decode bleu c > decode bleu c > decode bleu c > decode bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu
< extra_id_0 > c > base c > elmo c > rnet * c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c >
< extra_id_0 > table 6 shows the f1 score on conll - 2003 english ner task . “ # params ” : the parameter number in ner task . lstm * denotes the reported result .
< extra_id_0 > table 7 : test accuracy on snli and ptb task with base + ln setting and test perplexity on ptb task with base + ln setting . elrn outperforms glrn , elrn and elrn , respectively , in terms of accuracy and perplexity .
< extra_id_0 > b - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] r - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] r - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] # sent . c > [ italic ] w / system retrieval [ bold ] r - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] r - 2 and sent , respectively . c > [ italic ] w / system retrieval [ bold ] r - 2 and sent [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > top - 1 / 2 : % of evaluations a system being ranked as a best . top - 1 / 2 : % of evaluations a system being ranked as a best . top - 1 / 2 : % of evaluations a system being ranked as a best . the highest standard deviation among automatic systems is highlighted in bold , with statistical significance marked with ( approximation randomization test ) .
< extra_id_0 > dsim c > tlqs c > docsub c > docsub c > docsub c > docsub c > docsub c > hlqs c > hlqs c > hlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs cluster clust cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster clust cluster clust clust clust clust cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster
< extra_id_0 > dsim c > tlqs c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > hlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs cluster cluster cluster cluster cluster cluster clust cluster clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust
< extra_id_0 > slqs and docsub , respectively , and tf c > df c > docsub c > docsub cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster c
< extra_id_0 > dsim c > df c > docsub c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > c >
< extra_id_0 > dsim c > dsim c > docsub c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c >
< extra_id_0 > table 1 shows the performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned in table 1 . compared to the baseline , lf achieves a better performance ( ndcg % ) than the enhanced version as we mentioned in table 1 .
< extra_id_0 > table 2 shows the performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . using coatt , coatt and coatt , we see that p2 shows the best performance ( i . e . , hidden dictionary learning ) on different visdial models .
< extra_id_0 > fi - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > de - en c > bold > direct assessment / bold > zh - en c > bertscore - f1 c > 0 . 552 c > 0 . 538 c > 0 . 646 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > 0 . 646 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > c >
< extra_id_0 > > nat / bold > c > sfhotel bold > qual / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > and m2 respectively . for m1 and m2 , we use leic ( * ) and bertscore - recall ( * ) and m1 and m2 respectively . for m1 and m2 , we use spice ( * ) and bertscore - recall ( * ) and m1 and m2 respectively . for m1 and m2 , we use spice ( * ) and bertscore - recall ( * ) and m1 and m2 respectively . for m1 and m2 , we use bertscore - recall ( * ) and m1 and m1 and m2 respectively .
< extra_id_0 > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > c > c > c > c > c > c > c > c >
< extra_id_0 > transfer quality a > b > a > b > a > transfer quality tie sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim
< extra_id_0 > c > metric c > acc c > % of machine and human judgments that match c > 94 c > 84 c > human sentence - level validation of metrics ; 150 examples for sim and pp ; see text for validation of gm ; see text for validation of acc and pp .
< extra_id_0 > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m1 : m0 [ italic ] + para c > 0 . 818 c > 0 . 837 c > 18 . 8 c > gm c > m6 : m0 [ italic ] c >
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work , but untransferred sentences achieve the highest bleu than prior work at similar levels of acc . bleu is between 1000 transferred sentences and human references , and bleu is between 1000 untransferred sentences and human references .
< extra_id_0 > reparandum length [ bold ] 3 - 5 c > [ bold ] 3 - 5 c > reparandum length [ bold ] 3 - 5 c > rephrase c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 1 c > 1 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c >
< extra_id_0 > table 3 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both the reparandum and repair ( content - content ) , either in the reparandum or repair ( content - function ) , or in neither . the proportion of tokens belong to each category is shown in table 3 .
< extra_id_0 > [ bold ] dev mean c > [ bold ] dev best c > [ italic ] c > [ empty ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – –
< extra_id_0 > accuracy ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > performance comparison with the state - of - art algorithms on the fnc - 1 test dataset . our model achieves a better performance than the state - of - art algorithms .
< extra_id_0 > table 2 shows the accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models in terms of accuracy .
< extra_id_0 > table 3 shows the accuracy ( % ) comparisons of component models with and without attention . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > stage c > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] all c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold [ bold ] c > [ bold [ bold [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ]
< extra_id_0 > ( % ) and trigger [ bold ] identification ( % ) . c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] identification ( % ) c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold [ bold [ bold [ bold [ bold [ bold ] identification ( % ) c > [ bold [ bold [ bold ] identification ( % ) c > [ bold [ bold [ bold ] identification ( % ) c > [ bold [ bold [ bold
< extra_id_0 > wer
< extra_id_0 > > 50 % train dev c > 50 % train test c > full train test c > 75 % train dev c > 75 % train test c > cs - only c > 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > c > c > c > c > c > c > c > c > c > c > cs - only c > c > c > cs - only c > cs - only c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only
< extra_id_0 > table 5 summarizes the results on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > conll - 2003 shows that type - aggregated gaze features perform better on all three eye - tracking datasets and on the conll - 2003 dataset ( * marks statistically significant improvement ) . similarly , type - aggregated gaze features perform better on all three eye - tracking datasets and on all three conll - 2003 datasets .
< extra_id_0 > table 5 summarizes the performance of type - aggregated gaze features on the conll - 2003 dataset ( p , r , f1 - score , f1 - score , f1 - score , p , f1 - score , p , r , f1 - score , f1 - score , f1 - score , p , f1 - score , p , f1 - score , p , f1 - score , f1 - score , p , f1 - score , p , conll - 2003 gaze features on conll - 2003 dataset ( p , p , f , p , f , p , f , p , p , p , p , p , p , p , p , p , p , p , p , p , f , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 .
< extra_id_0 > table 1 shows the results on belinkov2014exploring ’ s ppa test set . lstm - pp and glove embeddings achieve 88 . 7 on the wordnet and verbnet test sets . ontolstm - pp and glove embeddings achieve 89 . 7 on the wordnet test set .
< extra_id_0 > c > [ bold ] full uas c > [ bold ] ppa acc . c > [ bold ] full uas c > [ bold ] ppa acc . c > 94 . 17 c > 88 . 51 c > c > c > c > c > c > c > c > c > c > c > rbg + hpcd ( full ) c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > table 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the ppa acc . the effect of removing sense priors and context sensitivity ( attention ) from the model is shown in table 3 .
< extra_id_0 > table 2 : adding subtitle data and domain tuning for image caption translation ( bleu % scores ) . all results with marian amun are shown in table 2 .
< extra_id_0 > and mscoco17 . the results show that subs1m and subs1m have significantly better performance than subs1m and lm + ms - coco . however , subs1m and lm + ms - coco have significantly worse performance than subs1m and lm + ms - coco .
< extra_id_0 > mscoco17 and en - de c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > en - de c >
< extra_id_0 > and mscoco17 . en - de c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c >
< extra_id_0 > mscoco17 and en - fr c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > en - fr c > en - fr c > en - fr c > en - fr c > mscoco17 c > mscoco17 c > mscoco17 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > ttr c > yule ’ s i c > mtld c > mtld c > en - fr - trans - ff c > 9 . 2793 c > en - fr - trans - ff c > 1 . 0925 c > 121 . 5801 c > en - fr - trans - back c > 9 . 2793 c > en - fr - trans - ff c > en - t
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . the train , test and development splits show the number of parallel sentences in the train , test and development splits for the languages we used .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . src and trg are used to train vocabularies for the english , french and spanish data used for our models .
< extra_id_0 > table 5 : automatic evaluation scores ( bleu and ter ) for the rev systems . the en - fr - rnn - rev system has a higher bleu score than the en - fr - smt - rev system .
< extra_id_0 > recall @ 10 ( % ) c > [ empty ] c > recall @ 10 ( % ) c > median rank c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > c > c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0
< extra_id_0 > recall @ 10 ( % ) c > rsaimage c > 0 . 0 c > chance c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0
< extra_id_0 > she turns in a u > screenplay screenplay that ’ s so clever you want hate hate hate hate hate . we report further examples in the appendix .
< extra_id_0 > bold > rnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > c
< extra_id_0 > bold > rnn / bold > bold > dan / bold > table 3 : sentiment score changes in sst - 2 . the numbers indicate the changes in percentage points with respect to the original sentence and vice versa .
< extra_id_0 > positive c > n ’ t c > evaluate c > conclusions r > c > best c > bad c > n ’ t c > evaluate c > conclude r > r > c > sift / bold > and bold > pubmed / bold > it c > n ’ t c > evaluate c > conclusions r > c > c > c > c > c > c > c > c > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold >
