< extra_id_0 > training c > throughput ( instances / s ) inference c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . fold performs the best on inference with efficient parallel
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 .
< extra_id_0 > the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations with different representation . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) without sdp and [ bold ] best f1 ( in 5 - fold ) with sdp . using the shortest dependency path on each relation type significantly improves the f1 score .
< extra_id_0 > c - f1 100 % c > r - f1 50 % c > r - f1 100 % c > r - f1 50 % c > r - f1 50 % c > r - f1 50 % c > r - f1 50 % c > r - f1 50 % c > r - f1 50 % c > f1 50 % c > y - 3 c > 51 . 59 c > 37 . 38 c > 37 . 89
< extra_id_0 > paragraph level acc . c > paragraph level c - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c >
< extra_id_0 > c > [ empty ] c > lstm - parser c > essay vs . paragraph level ; c - f1 ( 100 % ) in % for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the runs given in table 2 .
< extra_id_0 > bleu c > [ bold ] nist c > [ bold ] train c > test c > [ bold ] add c > wrong c > ser c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > bleu bleu bleu bleu bleu bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select bleu select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select
< extra_id_0 > ser ( % ) is significantly higher than that of the original e2e data ( see section 3 ) . ser ( % ) is significantly higher than the original e2e data ( see table 1 ) .
< extra_id_0 > nist c > [ bold ] train c > test c > [ bold ] add c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > miss c > select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select select
< extra_id_0 > table 4 shows the results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) . the results are presented in table 4 .
< extra_id_0 > graphlstm ( song et al . , 2018 ) and snrg ( song et al . , 2018 ) have the best performance . snrg and gcnseq have the best performance , whereas snrg and gcnseq have the worst performance . snrg and gcnseq have the best performance .
< extra_id_0 > amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . table 2 shows the model size in terms of parameters in terms of amr17 . ggnn2seq achieves 24 . 5 bleu points . dcgcn achieves 24 . 5 bleu points . ggnn2seq achieves 24 . 5 bleu points .
< extra_id_0 > english - czech b c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german b c > [ bold ] english - czech # p c > [ bold ] english - german b c > [ bold ] english - german b c > [ bold ] english - german b czech b c > c > c > [ beck et al . , 2017 ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > b c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > n c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > gcn + rc ( 2 ) has a b 16 . 8 and c 48 . 1 respectively . gcn + rc + la ( 2 ) has a b 16 . 8 and c 48 . 1 respectively . compared to baselines , gcn + rc + la ( 2 ) has a b 16 . 8 and c 47 . 9 respectively . compared to baselines , gcn + rc + la ( 2 ) has a b 16 . 8 and c 47 . 9 respectively . compared to baselines , gcn + rc + la ( 2 ) has a b 17 . 8 and c 17 . 9 respectively .
< extra_id_0 > d c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > c > # p c >
< extra_id_0 > c > b c > c c > - 4 dense blocks on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing dense connections .
< extra_id_0 > table 9 : ablation study for modules used in the graph encoder and the lstm decoder . the results are presented in table 9 . the decoder and the lstm encoder have significantly better performance than the encoder and lstm decoder , respectively .
< extra_id_0 > initialization c > depth c > objnum c > length c > coordinv c > glorot c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > subjnum c > depth c > tense c > objnum c > topconst c > depth c > depth c > depth c > depth c > depth c > depth c > depth c > depth c > depth c > depth c > depth c > objnum c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > mpqa c > mrpc c > trec c > sick - e c > sst5 c > sick - r c > hybrid cmow / 784 c > 90 . 0 c > [ bold ] 97 . 2 c > [ bold ] 97 . 2 c > [ bold ] 97 . 2 c > [ bold ] 97 . 2 c > [ bold ] 97 . 2 c > [ bold ] 97 . 2 c > [ bold 97 . 2 c > [ bold 97 . 2 c > [ bold 97 . 2 c > [ bold ] 97 . 2 c > [ bold ] 97 . 2 c > [ bold ] 97 . 2 c > [ bold ] 97 . 2 c > [ bold ] 97 . 2 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold ] 8 . 0 c > [ bold
< extra_id_0 > c > sts14 c > sts15 c > sts16 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp >
< extra_id_0 > mrpc and mpqa . mrpc and mpqa perform better than sick - e and sick - r . our paper outperforms glorot and sick - r in both initialization and sick - r . our paper outperforms glorot and sick - r in both initialization and sick - r .
< extra_id_0 > c > sts14 c > sts15 c > sts16 c > cmow - c c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ cbow - r c > c > [ bold - r c > [ bold - r c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ cbow - r c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ cbow - r c > [ bold ] c > [ c ] c > [ c ] c > [ c ] c > [ c ] c > [ c ] c > [
< extra_id_0 > tense c > objnum c > depth c > tense c > objnum c > topconst c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc cmow - c wc wc wc wc wc cmow - c wc cmow - c wc wc wc wc wc wc wc cmow - c wc wc wc wc wc wc cmow - c wc wc wc wc wc cmow - c wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc cmow - c wc wc wc
< extra_id_0 > mpqa c > mrpc c > mrpc c > sick - e c > sst5 c > sts - b c > sick - r c > cmow - c c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > mrpc c > c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ cbow - r ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ cbow - r ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ]
< extra_id_0 > all org c > all per c > all misc c > all loc c > all misc c > all misc c > all loc c > all org c > all per c > all misc c > all per c > all misc c > mil - nd c > 57 . 15 c > 89 . 46 c > 89 . 46
< extra_id_0 > all p c > all r c > all f1 c > in [ italic ] e + p c > in [ italic ] e + r c > in [ italic ] e + f1 c > all p c > all p c > all p c > all f1 c > 37 . 42 c > 37 . 38 0 . 68 c > 69 . 38 c > 69 . 38 c >
< extra_id_0 > gen con / bold > ref gen con / bold > ref gen con / bold > ref gen con / bold > ref gen con / bold > ref gen con / bold > ref gen ref gen s2s gin ref gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin
< extra_id_0 > > bold > bleu / bold > bold > meteor / bold > c > ldc2015e86 c > ldc2015e86 c > ldc2015e86 c > ldc2015e86 c > c > c > c > c > c > c > c > c > c > c > c > s2s - ggnn c >
< extra_id_0 > c > bold > model / bold > c > song et al . ( 2018 ) c > 200k c > 31 . 60 c > g2s - ggnn c > 200k c > 31 . 60 c > g2s - ggnn c > 200k c > 31 . 60 c > g2s - ggnn c > 200k c > 31 . 60 c >
< extra_id_0 > bold > meteor / bold > bold > size / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > bilstm c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > 0 - 7
< extra_id_0 > table 8 shows the fraction of elements in the output that are missing in the generated sentence ( added ) and the fraction of elements in the input that are missing in the generated sentence ( miss ) for the test set of ldc2017t10 . the token lemmas are used in the comparison .
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . table 4 : sem and pos tagging accuracy using features extracted from the nmt encoding layer .
< extra_id_0 > table 2 shows mft and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound is shown in table 2 .
< extra_id_0 > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging
< extra_id_0 > table 5 shows pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders are shown in table 5 .
< extra_id_0 > task c > sentiment c > sentiment c > mention c > sentiment c > sentiment c > mention c > mention c > gender c > 9 . 7 on a training set 10 % held - out , the attacker ’ s performance on different datasets is shown in table 8 . the difference between the attacker ’ s score and the adversary ’ s accuracy is shown in table 8 .
< extra_id_0 > c > task c > accuracy c > sentiment c > 67 . 4 r > c > [ empty ] c > [ italic ] gender c > 67 . 4 r > c > [ empty ] c > [ italic ] c > [ empty ] c > [ italic ] c > [ captcha ] c > [ captcha ] c > [ captcha ] c >
< extra_id_0 > dial c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced c > unbalanced acc c > unbalanced acc c > unbalanced acc c > unbalanced acc c > unbalanced acc c > unbalanced acc c > acc c > acc c > acc c > acc
< extra_id_0 > data c > mention c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > mention c > gender c > 72 . 5 c > 57 . 3 c > 6 . 9 cap > performances on different datasets with an adversarial training . the difference between the attacker score and the corresponding adversary ’ s accuracy is shown in table 3 .
< extra_id_0 > embedding guarded and leaky with different encoders . table 6 shows the accuracies of the protected attribute with different encoders . the guarded and leaky encoders have the best performance .
< extra_id_0 > ptb + finetune c > wt2 + dynamic c > ptb + finetune c > wt2 + dynamic c > yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared yang et al . ( 2018 ) compared to yang et al . ( 2018 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 )
< extra_id_0 > + bert acc c > + ln acc c > + bert time c > + ln + bert time c > + ln + bert time c > + ln + bert time c > + ln + bert time c > + ln + bert time c > + ln + bert time c > + ln + bert time c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > + ln acc c > + bert acc c > + ln acc c > + bert acc c > + ln acc c > + ln acc
< extra_id_0 > yahoo err c > yahoo time c > yelppolar err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > lstm c > c > c >
< extra_id_0 > bleu score on wmt14 english - german translation task . train and decode time in seconds measured from 0 . 2k training steps on tesla p100 . decode time in milliseconds measured from 0 . 2k training steps on tesla p100 . bleu score on newstest2014 dataset .
< extra_id_0 > table 4 : exact match / f1 - score on squad dataset . wang et al . ( 2017 ) . wang et al . ( 2017 ) . wang et al . ( 2017 ) .
< extra_id_0 > table 6 shows the f1 score on conll - 2003 english ner task . lstm * denotes the number of parameters in ner task .
< extra_id_0 > table 7 summarizes the results on snli and ptb task with base + ln setting and test perplexity on ptb task with base + ln setting . elrn outperforms glrn and glrn in accuracy and perplexity tests .
< extra_id_0 > b - 2 and r - 2 , respectively , and # sent . c > [ italic ] w / system retrieval [ bold ] r - 2 and r - 2 , respectively , and c > [ italic ] w / system retrieval [ bold ] r - 2 and r - 2 , respectively , and c > [ italic ] w / system retrieval [ bold ] # sent . c > [ italic ] w / system retrieval [ bold ] c > [ italic ] c > [ italic ] w / system retrieval [ bold ] r - 2 and cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster
< extra_id_0 > top - 1 / 2 : % of evaluations a system being ranked as a best . top - 1 / 2 : % of evaluations a system being ranked as a best . the highest standard deviation among automatic systems is 1 . 0 , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is highlighted in bold . the best result among automatic systems is highlighted in bold .
< extra_id_0 > tf c > dlqs c > docsub c > hclust c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > pt c > hclust c > pt c > pt c > pt c > pt c > pt c > pt c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster
< extra_id_0 > slqs and docsub perform better than df and hclust . europarl outperforms lang c > dsim c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > hclust c > 0 . 052 c > 0 . 052 cluster cluster
< extra_id_0 > tf c > df c > docsub c > hclust c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > hclust c > pt c > pt c > pt c > pt c > pt c > pt c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > clust c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > clust clust clust clust cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster
< extra_id_0 > slqs , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , totalterms , maxdepth , avgdepth , maxdepth , and avgdepth . europarl has the highest avgdepth and maxdepth . it has the lowest avgdepth and maxdepth , respectively , and docsub , respectively .
< extra_id_0 > slqs , df and docsub perform well on both corpus and hclust datasets . the results show that the europarl model outperforms all the corpus models in terms of avgdepth and avgdepth . the europarl model outperforms all the corpus models except for df and docsub .
< extra_id_0 > table 1 shows the performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as mentioned in table 1 . the qt and answer score sampling performed better than regressive and generalized ranking loss on the validation set of visdial .
< extra_id_0 > table 2 shows the performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . using coatt , coatt and coatt , we see that p2 indicates the most effective one ( i . e . hidden dictionary learning ) shown in table 1 .
< extra_id_0 > fi - en c > lv - en c > lv - en c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > cs - en and lv - en , respectively , and zh - en and zh - en , respectively . bertscore - f1 and ruse ( * ) score significantly better than bertscore - f1 , respectively .
< extra_id_0 > , and sfhotel bold > qual / bold > . sfhotel bold > qual / bold > achieves better performance than bleu - 1 and bleu - 2 , respectively . sfhotel achieves better performance than bleu - 1 and bleu - 2 , respectively .
< extra_id_0 > m1 and m2 respectively , and leic ( * ) c > 0 . 949 / bold > 0 . 750 / bold > 0 . 750 / bold > 0 . 750 / bold > 0 . 750 / bold > / bold > 0 . 750 / bold > / bold > / bold > 0 . 750 / bold > / bold > / bold > 0 . 750 / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > bertscore - recall / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > bertscore - recall / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > / d > /
< extra_id_0 > gm and sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m1 : m0 [ italic ] + cyc + para c > m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m4 : m0 : m0 : m0 : m0 : m0 : m0 : m4 : m0 : m4 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : cyc + para : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 + cyc + para : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 + cyc + para : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 + cyc + para : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m0 : m
< extra_id_0 > transfer quality a > b c > semantic preservation b > a c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim
< extra_id_0 > c > metric c > lit . c > human sentence - level validation of metrics ; 150 examples for sim and pp ; 150 for spearman ’ s [ italic ] and 150 for pp ; see text for validation of gm ; see text for validation of acc .
< extra_id_0 > gm and sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m1 : m0 [ italic ] + cyc + para c > 0 . 818 c > 27 . 3 c > 21 . 6 c >
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work , but untransferred sentences achieve the highest bleu than prior work at similar levels of acc . our best models achieve higher bleu than our best models achieve higher bleu than previous work at similar levels of bleu .
< extra_id_0 > reparandum length [ bold ] 3 - 5 . reparandum length [ bold ] 3 - 5 . reparandum length [ bold ] 6 - 8 . rephrase and restart tokens have higher accuracy than rephrase and restart tokens , respectively . rephrase and restart tokens have higher accuracy than rephrase and restart tokens .
< extra_id_0 > reparandum length [ bold ] 3 - 5 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both the reparandum and repair ( content - content ) or in neither the reparandum or repair ( content - function ) or in neither .
< extra_id_0 > [ bold ] dev mean c > [ bold ] test best c > [ italic ] c > [ bold ] dev mean c > [ bold ] dev best c > [ bold ] dev mean c > [ bold ] test mean c > [ bold ] dev best c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] – c > [ italic ] – c > [ italic ] – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – –
< extra_id_0 > accuracy ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > 81 . 72 c > performance comparison with the state - of - art algorithms on the fnc - 1 test dataset . our model achieves a higher accuracy than the state - of - art ones .
< extra_id_0 > table 2 shows the accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models .
< extra_id_0 > table 3 shows the accuracy ( % ) comparisons of component models with and without attention . the results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > all c > [ bold ] stage c > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] all c > [ bold ] stage c > [ bold ] trigger c > embedding + t c > 75 . 3 c > 69 . 8 c > 69 . 8 c > embedding + t c > 75 . 3 c > 69 . 8 c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold [ bold [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > [ bold ] c > [ bold [ bold ] c > [ bold [ bold ] c > embedding + t c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > embedding + t c > c > c > c
< extra_id_0 > c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) f1 cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster ( % ) cluster
< extra_id_0 > wer c > dev perp c > test perp c > test wer c > test perp c > test wer c > test perp c > test perp c > test perp c > test wer c > all : cs - only - lm c > 68 . 61 c > 57 . 9 c >
< extra_id_0 > train dev and full train test set using discriminative training with only subsets of the code - switched data . cs - only achieves the best performance on the dev set and on the test set using discriminative training .
< extra_id_0 > table 5 summarizes the results on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) . on the dev set and on the test set , the accuracy on the dev set and on the test set is significantly higher than on the test set .
< extra_id_0 > c > [ bold ] p , recall ( r ) and f1 - score ( f1 ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( table 7 ) .
< extra_id_0 > c > [ bold ] p , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) . type - aggregated gaze features on the conll - 2003 dataset are shown in table 5 .
< extra_id_0 > table 1 summarizes the results on belinkov2014exploring ’ s ppa test set . lstm - pp and glove embeddings show the best performance . ontolstm - pp and glove - extended embeddings show the best performance . ontolstm - pp and glove - retro embeddings show the best performance .
< extra_id_0 > table 2 summarizes results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachments . the results show that rbg + hpcd ( full ) outperforms rbg in terms of ppa accuracies .
< extra_id_0 > [ bold ] ppa acc . c > 89 . 7 c > - sense priors and context sensitivity ( attention ) from the model . the effect of removing sense priors and context sensitivity ( attention ) from the model is shown in table 3 .
< extra_id_0 > adding subtitle data and domain tuning for image caption translation ( bleu % scores ) . all results with marian amun are summarized in table 2 .
< extra_id_0 > and mscoco17 . we observe that subs1m [ italic ] and lm + ms - coco outperform domain - tuned and lm + ms - coco in terms of labeling . we observe that subs1m [ italic ] and lm + ms - coco outperforms both domain - tuned and lm + ms - coco in terms of labeling . we observe that lm + ms - coco outperforms both domain - tuned and en - de
< extra_id_0 > autocap 1 ( concat ) and autocap 2 ( dual attn . ) perform better than autocap ( dual attn . ) on the multi30k and multi30k datasets , respectively . adding automatic image captions to en - de and mscoco17 datasets improves the performance of both en - de and mscoco17 datasets . adding autocap 1 ( concat ) improves the performance of both en - de and mscoco17 datasets , respectively .
< extra_id_0 > and mscoco17 . we observe that enc - gate and dec - gate achieve better performance than enc - gate and dec - gate , respectively . we observe that enc - gate and dec - gate achieve better performance than enc - gate and enc - gate , respectively . we observe that enc - gate and dec - gate achieve better performance than enc - gate and enc - gate , respectively , while enc - gate achieve better performance than enc - gate ( table 2 ) .
< extra_id_0 > and flickr < extra_id_1 > and mscoco17 , respectively . subs3m and subs6m perform better than en - fr and en - fr en - fr en - fr and mscoco17 , respectively , and en - fr and mscoco17 , respectively , and mscoco17 and mscoco17 , respectively . compared to en - fr and mscoco17 , mscoco17 and subs3m , respectively , respectively , respectively , respectively .
< extra_id_0 > 476 and 109 . 4749 respectively . mtld and en - fr - trans - ff achieve better performance than en - fr - trans - back and en - fr - trans - back , respectively . mtld and en - fr - trans - back achieve better performance than en - fr - trans - back and en - fr - trans - back , respectively .
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . en – es has a total of 1 , 472 , 203 parallel sentences in the train , test and development splits , and en – es has 459 , 633 parallel sentences .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . using the src and trg datasets , we find that the training vocabularies for the english , french and spanish datasets is significantly better than those for the spanish and english datasets .
< extra_id_0 > table 5 shows the automatic evaluation scores ( bleu and ter ) for the rev systems ( en - fr - rnn - rev and en - fr - smt - rev ) .
< extra_id_0 > recall @ 10 ( % ) and median rank ( 0 . 0 ) on flickr8k . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala 2017 .
< extra_id_0 > recall @ 10 ( % ) c > rsaimage c > 0 . 0 c > chance c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0
< extra_id_0 > she turns in a u > screenplay that u > at the edges edges edges curves so clever you want hate hate hate hate hate hate hate . we report further examples in the appendix .
< extra_id_0 > bold > rnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnncnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold >
< extra_id_0 > the numbers indicate the changes in percentage points with respect to the original sentence . the last two rows correspond to the case where negative labels are flipped to positive and vice versa . the number of percentage points indicates that the score increases in positive and negative sentiment .
< extra_id_0 > not evaluate c > evaluate c > evaluate c > evaluate c > conclude r > compared to bold > sst - 2 / bold > and bold > pubmed / bold > . compared to bold > sst - 2 / bold > and bold > sst - 2 / bold > , pmi c > love c > bad c > evaluate c > evaluate c > conclude c > conclusions .
