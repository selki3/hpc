< extra_id_0 > table 2 shows the throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . the recursive approach performs the best on inference with efficient parallel execution of tree nodes , while the folding technique shows better performance on training thanks to its gpu exploitation .
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 .
< extra_id_0 > the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) with sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) with sdp without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > + 27 . 82 c > + 27 . 82 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > c - f1 100 % c - f1 50 % c - f1 100 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c
< extra_id_0 > paragraph level c - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > essay level f1 c > essay level f1 c >
< extra_id_0 > c > [ empty ] c > lstm - parser c > [ empty ] c > lstm - parser c > ( 100 % ) in c - f1 ( 100 % ) in % for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the runs given in table 2 . note that the average performance is lower than the majority performance over the two indicated systems .
< extra_id_0 > train c > test c > train c > train c > test c > train c > train c > train c > test c > train c > train c > train c > test c > train c > train c > test c > train c > test c > train c > test c > train c > test c > train c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test bleu c > test bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu
< extra_id_0 > cap > table 1 : data statistics comparison for the original e2e data and our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by our slot matching script , see section 3 ) . cap > table 1 : data statistics comparison for the original and our cleaned version .
< extra_id_0 > bleu cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider
< extra_id_0 > table 4 : results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies , slight disfluencies ) .
< extra_id_0 > graphlstm ( song et al . , 2018 ) and tree2seqk ( song et al . , 2018 ) have the best performance . graphlstm ( song et al . , 2018 ) has the best performance . snrg ( song et al . , 2017 ) has the best performance . snrg ( song et al . , 2017 ) has the best performance .
< extra_id_0 > gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . ggnn2seq achieves 24 . 5 bleu points on amr17 . ggnn2seq achieves 24 . 5 bleu points on amr17 . ggnn2seq achieves 24 . 5 bleu points on amr17 . ggnn
< extra_id_0 > german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german # p c > [ bold ] english - german # p c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > 2 c > 1 c > 2 c > 2 c > 50 . 3 r > c > c > c > 1 c > 1 c > 20 . 0 c > 50 . 3 r > c > c > 50 . 5 r > c > c > c > c > c > c > c > 22 . 0 c > c > c > c >
< extra_id_0 > + rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denoted in table 6 .
< extra_id_0 > d c > b c > c c > d c > d c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ]
< extra_id_0 > table 8 : ablation study for density of connections on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > table 9 : ablation study for modules used in the dcgcn4 encoder and the lstm decoder . the lstm encoder and lstm decoder perform better than the encoder and the lstm decoder , respectively .
< extra_id_0 > initialization c > depth c > objnum c > tense c > coordinv c > topconst c > glorot c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > subjnum c > depth c > tense c > objnum c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > wc c >
< extra_id_0 > mpqa c > mpqa c > mpqa c > mpqa c > mpqa c > mrpc c > hybrid c > sick - e c > 79 . 2 c > 79 . 6 c > 87 . 6 c > 87 . 6 c > 87 . 6 c > 87 . 6 c > 87 . 6 c > 87 . 6
< extra_id_0 > c > sts14 c > sts15 c > sts16 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > < extra_id_1 >
< extra_id_0 > compared to mrpc and mpqa . mrpc and mpqa perform better than glorot and sick - e and sick - r . glorot and sick - r perform better than glorot and sick - r and sick - r .
< extra_id_0 > c > sts14 c > sts15 c > sts16 c > cmow - c c > [ bold ] 31 . 9 c > [ bold ] 43 . 5 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ cbow - c ] c > [ bold - c ] c > [ bold - c ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold - r ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] 57 . 9 c > [ bold ] 57 . 9 c > [ bold ] 57 . 9 c > [ bold ] 57 . 9 c > [ bold ] 57 . 9 c > [ bold ] 57 . 9 c > [ bold ] 57 . 9 c > [ bold ] 57 . 9 c > [ bold ] 57 . 9 c > [ bold ] 57 .
< extra_id_0 > compared to bshift and topconst . cmow - c performs better than bshift and topconst . cmow - r performs better than bshift and topconst . cmow - r performs better than bshift and topconst . cmow - r performs better than cmow - r and topconst .
< extra_id_0 > mrpc c > mpqa c > mpqa c > mrpc c > sick - e c > sst5 c > sick - r c > cmow - c c > 79 . 9 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > cmow - r c >
< extra_id_0 > all loc c > all org c > all misc c > all misc c > all loc c > all org c > all misc c > all org c > all misc c > mil - nd c > 57 . 15 c > 89 . 46 c > 89 . 46 c > 89 . 46 c > 89 . 46 c > 89 . 46 c >
< extra_id_0 > all p c > all r c > all f1 c > in [ italic ] e + p c > in [ italic ] e + r c > in [ italic ] e + r c > all f1 c > 69 . 38 0 . 68 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c >
< extra_id_0 > gen bold > ent / bold > c > ref gen bold > neu / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > > meteor / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > g2s - gin c > 22 . 55 0 . 17 0 . 16 0 . 16 0 . 16 0 . 16 0 . 16 bold > bold > bold > bold > bold > bold > bold > bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > bold > model / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold
< extra_id_0 > bold > meteor / bold > bold > size / bold > c > 57 . 6m c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > 0 - 7
< extra_id_0 > table 8 shows the fraction of elements in the output that are not present in the input ( added ) and the fraction of elements in the input graph that are missing in the generated sentence ( miss ) , for the test set of ldc2017t10 . the token lemmas are used in the comparison .
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . table 4 : sem and pos tagging accuracy using features extracted from the nmt encoding layer .
< extra_id_0 > table 2 shows the pos and sem tagging accuracy with baselines and an upper bound . the pos and sem tagging accuracy with baselines and an upper bound is shown in table 2 .
< extra_id_0 > ru c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh .
< extra_id_0 > pos and 3 91 . 8 pos scores outperform uni and bidirectional encoders in terms of pos and sem tagging accuracy , averaged over all non - english target languages . uni and bidirectional encoders perform better than bi and bidirectional encoders in terms of pos and sem .
< extra_id_0 > task c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > mention c > mention c > gender c > 9 . 7 cap > attacker ’ s performance on different datasets
< extra_id_0 > data c > task c > accuracy c > sentiment c > 67 . 4 c > [ empty ] c > [ italic ] pan16 c > [ empty ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > mention c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > data c > dial c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment
< extra_id_0 > data c > task acc c > leakage c > 5 . 0 on different datasets with an adversarial training . is the difference between the attacker score and the corresponding adversary ’ s accuracy .
< extra_id_0 > table 6 : accuracies of the protected attribute with different encoders . embedding leaky c > 64 . 5 c > 67 . 8 c > embedding guarded c > 54 . 8 c > 59 . 3 c > 54 . 8 c > 59 . 3 c > 54 . 8 c > table 6 : accuracies of the protected attribute with different encoders .
< extra_id_0 > ptb + finetune c > wt2 + dynamic c > ptb + finetune c > ptb + finetune c > wt2 + dynamic c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c >
< extra_id_0 > + bert time c > + ln acc c > + bert time c > + ln time c > + bert time c > + ln time c > + bert time c > + ln time c > + bert time c > + ln time c > c > c > c > c > c > c > c > c >
< extra_id_0 > amapolar time c > yahoo err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > zhang et al . ( 2015 ) c >
< extra_id_0 > model c > # params c > train c > decode c > train c > train c > decode c > train c > train c > decode c > train c > decode c > train c > decode c > decode c > decode c > decode c > decode c > decode c > train c > decode c > decode c > decode bleu c > decode c > decode c > decode bleu c > decode bleu c > decode bleu c > decode bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bl
< extra_id_0 > c > base c > elmo c > rnet * c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c >
< extra_id_0 > table 6 shows the f1 score on conll - 2003 english ner task . “ # params ” denotes the parameter number in conll - 2003 english ner task .
< extra_id_0 > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting and test perplexity on snli task with base + ln setting and test accuracy on snli task with ptb task with base + ln setting .
< extra_id_0 > b - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] # word c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] c > 66 c > 22 c > 66 c > 22 c > 22 c > 22 c > 22 c > 66 c > 22 c > 66 c > 22 c > 66 c > 22 c > 66 c > 22 c > 66 c > 66 c > 66 c > 22 c > 66 c > 22 c > 22 c > 22 c > 22 c > - c > - c > - c > - c > - c > - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
< extra_id_0 > top - 1 / 2 : % of evaluations a system being rated as being a best . top - 1 / 2 : % of evaluations a system being rated as being a best . the highest standard deviation among automatic systems is highlighted in bold , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the best result among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is 1 . 0 .
< extra_id_0 > tf c > dsim c > docsub c > docsub c > docsub c > docsub c > hclust c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > hclust c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df c > df cluster clust cluster clust cluster clust cluster clust cluster clust cluster clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust c
< extra_id_0 > slqs and tf c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > hlqs c > hlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs c > tlqs cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster clust cluster clust cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster
< extra_id_0 > tf c > dsim c > docsub c > hclust c > df c > df c > df c > df c > df c > df c > df c > df c > df c > hclust c > df c > df c > df c > df c > df c > df c > df cluster cluster cluster cluster cluster cluster clust cluster cluster clust cluster cluster clust cluster clust cluster clust cluster cluster cluster cluster cluster cluster cluster clust cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster
< extra_id_0 > dsim and slqs and docsub and hclust perform better than corpus c > dsim and docsub c > dsim and docsub c > hclust cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster clust cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster c
< extra_id_0 > dsim and slqs . dsim and slqs perform better than the other corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus hclust corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corpus corp
< extra_id_0 > table 1 shows the performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned in table 1 . lf is the baseline version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set is shown in table 1 .
< extra_id_0 > table 2 shows the performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . p2 indicates the most effective one ( i . e . hidden dictionary learning ) shown in table 1 .
< extra_id_0 > fi - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > de - en c > bold > direct assessment / bold > fi - en c > bold > direct assessment / bold > zh - en c > bertscore - f1 c > 0 . 552 c > 0 . 538 c > 0 . 646 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > 0 . 610 c > 0 . 646 c > 0 . 610 c > c >
< extra_id_0 > - nat and sfhotel bold > qual / bold > sfhotel bold > qual / bold > sfhotel bold > qual / bold > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > and m2 respectively . bertscore - recall c > 0 . 809 c > 0 . 749 c > 0 . 750 r > bertscore - recall c > 0 . 709 c > 0 . 750 r > bertscore - recall c > 0 . 709 c > 0 . 750 r > bertscore - recall c > 0 . 709 c > 0 . 750 r > 0 . 749 r >
< extra_id_0 > shen - 1 and cyc + para c > 0 . 728 c > 63 . 2 c > gm c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m1cyc + para c > m4cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paracyc + paralang c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > transfer quality a > b and transfer quality tie sim c > semantic preservation a > b and transfer quality tie sim c > semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie sim c > semantic preservation tie sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim
< extra_id_0 > table 5 shows the validation of acc and pp on yelp and lit . acc is the number of machine and human judgments that match compared to spearman ’ s and spearman ’ s ( see text for validation of gm ) . spearman ’ s and spearman ’ s ( see text for validation of gm ) and spearman ’ s ( see text for validation of gm ) . spearman ’ s ( see text for validation of gm ) and spearman ’ s ( see text ) .
< extra_id_0 > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m1 : m0 [ italic ] + para c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > m6 : m0 [ italic ] + cyc + para c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > gm c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work at similar levels of acc , but untransferred sentences achieve the highest bleu than prior work at similar levels of bleu . bleu is between 1000 transferred sentences and human references , and bleu is between 1000 transferred sentences and human references . our best models achieve higher bleu than previous work , but untransferred sentences achieve the highest bleu .
< extra_id_0 > table 2 : percent of reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 .
< extra_id_0 > table 3 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both the reparandum and repair ( content - content ) , either the reparandum or repair ( content - function ) , or in neither . the proportion of tokens belong to each category is shown in table 3 .
< extra_id_0 > [ bold ] dev mean c > [ bold ] dev best c > [ italic ] c > [ bold ] dev mean c > [ bold ] dev best c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ empty ] c > [ bold ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – –
< extra_id_0 > accuracy ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > performance comparison with the state - of - art algorithms on the fnc - 1 test dataset . our model performs better than the state - of - art algorithms .
< extra_id_0 > the unified model significantly outperforms all previous models on the apw and nyt datasets ( higher is better ) . the unified model significantly outperforms all previous models on the document dating problem ( higher is better ) .
< extra_id_0 > table 3 shows the accuracy ( % ) comparisons of component models with and without attention . the results show the effectiveness of word attention and graph attention for this task . please see section 6 . 2 for more details .
< extra_id_0 > [ bold ] 1 / n c > [ bold ] 1 / n c > [ bold ] 1 / n c > [ bold ] all c > [ empty ] c > embedding + t c > 68 . 1 c > 36 . 6 c > 59 . 8 c > [ empty ] c > [ empty ] c > [ empty ] c > [ bold ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] f1 c > [ bold ] f1 c > [ bold ] f1 c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold ] c > [ bold c > [ bold ] c > [ bold ] c > [ bold c > [ bold ] c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold
< extra_id_0 > wer
< extra_id_0 > > 50 % train dev c > 50 % train test c > 75 % train dev c > full train test c > 75 % train dev c > cs - only c > 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > cs vs . monolingual ( mono ) in the dev set and on the test set . fine - tuned - lm achieves better accuracy than fine - tuned - lm on the dev set and on the test set .
< extra_id_0 > table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset are shown in table 7 .
< extra_id_0 > table 5 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) . using type - aggregated gaze features on the conll - 2003 dataset is shown in table 5 .
< extra_id_0 > table 1 summarizes the results on belinkov2014exploring ’ s ppa test set . lstm - pp and glove - retro perform better than lstm - pp and lstm - pp embeddings , respectively .
< extra_id_0 > table 2 summarizes results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachment predictors . the rbg dependency parser with features coming from hpcd ( full ) and hpcd ( full ) achieves 94 . 17 points .
< extra_id_0 > table 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the ppa acc . the effect of removing sense priors and context sensitivity ( attention ) from the model is shown in table 3 .
< extra_id_0 > adding subtitle data and domain tuning for image caption translation ( bleu % scores ) . all results with marian amun are shown in table 2 .
< extra_id_0 > and mscoco17 . we observe that subs1m ( lm + ms - coco ) outperforms subs1m ( lm + ms - coco ) and lm + ms - coco ( lm + ms - coco ) . we observe that subs1m ( lm + ms - coco ) outperforms subs1m ( lm + ms - coco ) and lm + ms - coco ( lm + ms - coco ) . we observe that subs1m ( lm + ms - cococo ) outperforms t
< extra_id_0 > autocap 1 - 5 ( concat ) and autocap 1 - 5 ( concat ) perform better than autocap ( dual attn . ) and autocap ( dual attn . ) on multi30k and multi30k datasets . adding automatic image captions in table 4 shows that autocap 1 - 5 ( concat ) performs better than autocap ( dual attn . ) on multi30k datasets .
< extra_id_0 > and mscoco17 . en - de c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > enc - gate c > enc - gate c >
< extra_id_0 > mscoco17 and en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > mscoco17 c > mscoco17 c > mscoco17 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > 8776 and 109 . 4506 respectively . mtld and en - fr - trans - ff perform better than en - fr - trans - back and en - fr - trans - back , respectively . mtld and en - fr - trans - back perform better than en - fr - trans - back and en - fr - trans - back , respectively .
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . the number of parallel sentences in the train , test and development splits is similar to the number of parallel sentences in the train , test and development splits .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . the training vocabularies for the english , french and spanish data used for our models are shown in table 2 .
< extra_id_0 > table 5 shows the automatic evaluation scores ( bleu and ter ) for the rev systems . the en - fr - rnn - rev system has a higher bleu score than the en - fr - trans - rev system .
< extra_id_0 > recall @ 10 ( % ) c > [ empty ] c > recall @ 10 ( % ) c > median rank c > 0 . 0 c > rsaimage c > 0 c > 0 . 0 c > 0 . 0 c > 0 . 0 c > 0 . 0 c > 0 . 0 c > 0 . 0 c > 0 . 0 c > 0 . 0 c > 0 . 0 c > 0 . 0 c > c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c >
< extra_id_0 > recall @ 10 ( % ) c > rsaimage c > 0 . 5 c > chance c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0
< extra_id_0 > she turns in a u > screenplay screenplay that ’ s so clever you want hate hate hate hate hate hate . we report further examples in the appendix . we report further examples in table 1 .
< extra_id_0 > bold > rnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > cnn / bold > c
< extra_id_0 > bold > rnn / bold > bold > dan / bold > table 3 : sentiment score changes in sst - 2 . the numbers indicate the changes in percentage points with respect to the original sentence and vice versa .
< extra_id_0 > better than pubmed and sst - 2 and sst - 2 are better than pubmed and pubmed . moreover , it is better than sst - 2 and pubmed , but it is better than sst - 2 and sst - 2 . moreover , it is better than sst - 2 and sst - 2 , but it is better than sst - 2 and pubmed . moreover , it is better than sst - 2 and pubmed . moreover , it is better than sst - 2 , but it is worse .
