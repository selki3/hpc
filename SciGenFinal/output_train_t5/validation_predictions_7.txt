< extra_id_0 > training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s )
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases to 25 .
< extra_id_0 > [ bold ] hyper parameter optimization results for each model with different representation . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all models with different representation . the max pooling strategy consistently performs better in all model variations .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > + 19 . 90 c >
< extra_id_0 > 50 % c - f1 100 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c > c >
< extra_id_0 > paragraph level c - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c
< extra_id_0 > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c >
< extra_id_0 > train c > [ bold ] system c > [ bold ] train c > [ bold ] system c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c >
< extra_id_0 > mrs c > 4 , 862 c > 42 , 061 c > 17 . 69 c > ( 0 . 001 ) c > [ bold ] train c > 4 , 862 c > 4 , 672 c > ( 0 . 001 ) c > ( 0 . 001 ) c > [ 0 . 5pt / 2pt ] cleaned train c > 1 , 358 c > 4 , 693 c > ( 0 . 001 ) c > ( 0 . 001 ) c >
< extra_id_0 > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ]
< extra_id_0 > table 4 : results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies , slight disfluencies ) .
< extra_id_0 > 22 . 0 r > graphlstm ( song et al . , 2018 ) c > - c > 24 . 4 r > graphlstm ( song et al . , 2018 ) c > - c > 24 . 4 r > graphlstm ( song et al . , 2018 ) c > - c > 24 . 4 r > graphlstm ( song et al . , 2018 ) c > c > 24 . 4 c > 24 . 4 r > c > 24 . 4 r > c > c > c > c > c > c > c > 24 . 4 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . ggnn2seq ( beck et al . , 2018 ) achieves 24 . 5 bleu points on amr17 . ggnn2seq ( beck et al . , 2018 ) achieves 24 . 5 bleu points on amr17 .
< extra_id_0 > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold c > [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold c > [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] c > [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold [ bold [ bold [ bold ] [ bold [ bold [ bold ] [ bold ] [ bold ] [ bold [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold [ bold ] [ bold ] [ bold ] [ bold [ bold [ bold ] [ bold [ bold ] [ bold [ bold ] [ bold ] [ b
< extra_id_0 > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] c > [ italic ] n
< extra_id_0 > table 6 : comparisons with baselines . + rc ( 2 ) c > b 16 . 8 c > c 48 . 1 c > [ bold ] gcn + rc ( 2 ) c > b 16 . 8 c > [ bold ] + rc + la ( 2 ) c > c 47 . 9 c > [ bold ] 52 . 9 c > [ bold ] 52 . 9 c > [ bold ] 52 . 9 c > [ bold ] 52 . 9 c > + rc
< extra_id_0 > 20 . 9m c > 20 . 9m c > 20 . 9m c > 20 . 9m c > 22 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 23 . 9m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > 24 . 4m c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > table 8 : ablation study for density of connections on the dev set of amr15 . - i dense block denotes removing dense connections in the i - th block . - i dense block denotes removing dense connections in the i - th block . - i dense block denotes removing dense connections in the i - th block .
< extra_id_0 > c > 25 . 5 c > 55 . 4 c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c >
< extra_id_0 > c > initialization c > depth c > objnum c > tense c > topconst c > glorot c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ]
< extra_id_0 > method c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst
< extra_id_0 > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c >
< extra_id_0 > c > sts14 c > sts15 c > sts16 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > sick - e c > sick - b c > sick - b c > sick - b c > sick - b c > sick - b c > sick - b c > mrpc c > mrpc c >
< extra_id_0 > c > sts13 c > sts14 c > sts15 c > sts16 c > cmow - c c > [ bold ] 43 . 5 c > [ bold ] 52 . 2 c > [ bold ] 43 . 5 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold
< extra_id_0 > 81 . 1 c > wc c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > wc c >
< extra_id_0 > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > sick - e c > sick - b c > mrpc c > sick - r c > cmow - r c > [ bold ] 90 . 0 c > [ bold ] 88 . 0 c > [ bold ] 88 . 0 c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] .
< extra_id_0 > all loc c > all org c > all misc c > in [ italic ] e + loc c > all org c > all misc c > all org c > all org c > all misc c > all org c > all org c > all org c > all org c > all misc c > all org c > all mi
< extra_id_0 > all p c > all r c > all f1 c > in [ italic ] e + p c > in [ italic ] e + r c > in [ italic ] e + f1 c > in [ italic ] e + p c > in [ italic ] e + r c > in [ italic ] e + r c > in [ italic ] e + f1 c > c > c >
< extra_id_0 > bold > ent / bold > bold > neu / bold > bold > ent / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold >
< extra_id_0 > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > ldc2015e86
< extra_id_0 > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold >
< extra_id_0 > bold > meteor / bold > bold > size / bold > bold > meteor / bold > bold > size / bold > bold > size / bold > bold > size / bold > bold > size / bold > bold > size / bold > bold > size / bold >
< extra_id_0 > 7 - 13
< extra_id_0 > bold > added / bold > bold > miss / bold > bold > added / bold > bold > added / bold > bold > miss / bold > bold > added / bold > bold > added / bold > bold > miss / bold > bold > added / bold > bold
< extra_id_0 > fr c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c
< extra_id_0 > table 2 shows mft and unsupemb tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound .
< extra_id_0 > ru c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c
< extra_id_0 > table 5 : pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual encoders .
< extra_id_0 > task c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentim
< extra_id_0 > table 1 : accuracies when training directly towards a single task . mention c > 67 . 4 r > [ italic ] gender c > 67 . 4 r > [ empty ] mention c > 67 . 4 r > [ italic ] sentiment c > 67 . 4 r > [ italic ] mention c > 67 . 4 r > [ italic ] mention c >
< extra_id_0 > c > 67 . 4 c > 64 . 5 c > 79 . 5 c > 73 . 5 c > unbalanced leakage c > unbalanced leakage c > 73 . 5 c > unbalanced leakage c > 73 . 5 c > unbalanced leakage c > 59 . 4 c > 59 . 4 c > 59 . 7 c > 59 . 4
< extra_id_0 > c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment
< extra_id_0 > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c >
< extra_id_0 > wt2 + finetune c > wt2 + dynamic c > ptb base c > ptb + finetune c > wt2 + dynamic c > wt2 + finetune c > wt2 + finetune c > wt2 + finetune c > wt2 + dynamic c > yang et al . ( 2018 ) c >
< extra_id_0 > base time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > c > + bert
< extra_id_0 > model c > yelppolar err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time
< extra_id_0 > train c > decode c > train c > train c > train c > decode c > train c > train c > train c > decode c > train c > train c > train c > decode c > train c > train c > train c > decode c > train c > train c > decode c > decode
< extra_id_0 > “ # params ” : the parameter number of base . rnet * : results published by wang et al . ( 2017 ) . “ # params ” : the parameter number of base .
< extra_id_0 > “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task .
< extra_id_0 > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting . cap > table 7 : test accuracy on snli task with base + ln setting .
< extra_id_0 > retrieval [ bold ] b - 2 c > [ italic ] w / system retrieval [ bold ] b - 4 c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system
< extra_id_0 > the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is highlighted in bold . the best results among automatic systems are highlighted in bold .
< extra_id_0 > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs
< extra_id_0 > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c >
< extra_id_0 > slqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c >
< extra_id_0 > dsim c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs
< extra_id_0 > 980 c > 1 , 031 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c > 1 , 049 c >
< extra_id_0 > lf is the enhanced version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 .
< extra_id_0 > baseline c > lf c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > c >
< extra_id_0 > fi - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > c > c >
< extra_id_0 > lv - en c > bold > direct assessment / bold > fi - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > bold > direct assessment / bold >
< extra_id_0 > > qual / bold > bold > inf / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual
< extra_id_0 > m1 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m1 m2 m2 m1 m2 m1 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 .
< extra_id_0 > m0 : shen - 1 c > 0 . 694 c > 0 . 728 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ cyc
< extra_id_0 > models a c > models b c > models a c > models b c > models b c > models a c > models b c > models b c > models b c > models b c > models a c > models b c > models b c > models b c > models b c > models b c >
< extra_id_0 > c > metric c > method of validation c > yelp c > lit . c > acc c > % of machine and human judgments that match c > 94 c > 84 c > spearman ’ s [ italic ] and spearman ’ s [ italic ] b / w negative pp and human ratings of fluency c > 0 . 79 c > 0 . 67 c >
< extra_id_0 > 37 . 3 c > 10 . 0 c > gm c > pp c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c >
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work at similar levels of acc , but untransferred sentences achieve the highest bleu than previous work at similar levels of bleu . our best models achieve higher bleu than previous work at similar levels of acc . our best models achieve the highest bleu than previous work at similar levels of bleu .
< extra_id_0 > reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > 0 c > 0 c >
< extra_id_0 > 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] type c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > content - content c > 0 . 61 ( 30 % ) c > 0 . 58 ( 52 % ) c > 0 . 81 ( 32 % ) c > 0 . 80 ( 32 % )
< extra_id_0 > [ bold ] dev mean c > [ bold ] test mean c > [ bold ] test mean c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > average of word2vec embedding c > 12 . 43 c > 01 . 30 c > 53 . 24 c > 79 . 53 c > 81 . 72 c > [ bold ] 83 . 54 c > [ bold ] 83 . 54 c > [ bold ] 83 . 54 c > our model c >
< extra_id_0 > apw c > 38 . 5 c > 38 . 5 c > 42 . 5 c > oe - gcn c > 63 . 9 c > ac - gcn c > 60 . 3 c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold )
< extra_id_0 > table 3 : accuracy ( % ) comparisons of component models with and without attention . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] 1 / n c > [ bold ] all c > [ bold ] embedding + t c > 68 . 1 c > 36 . 6 c > 59 . 8 c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empt
< extra_id_0 > ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ italic ] f1 c > [ italic ]
< extra_id_0 > acc
< extra_id_0 > c > 50 % train dev c > 50 % train test c > 75 % train dev c > 75 % train test c > cs - only c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ]
cap > table 5 : accuracy on the dev set and on the test set according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . the conll - 2003 dataset has a baseline of 72 . 80 c > 56 . 97 c > 63 . 92 .
< extra_id_0 > p , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) . cap > table 5 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) .
< extra_id_0 > hpcd ( full ) is from the original paper , and it uses syntactic skipgram . glove - retro is a glove vector retrofitted to wordnet 3 . 1 , and glove - extended is a glove vector retrofitted to wordnet 3 . 1 .
< extra_id_0 > c > [ bold ] full uas c > [ bold ] ppa acc . c > [ bold ] full uas c > [ bold ] ppa acc . c > [ bold ] full uas c > [ bold ] rbg + hpcd ( full ) c > 94 . 17 c > 88 . 51 c > rbg + hpcd ( full ) c > 94 . 11 c >
< extra_id_0 > [ bold ] ppa acc . r > 89 . 7 c > - sense priors 88 . 4 c > - context sensitivity ( attention ) 88 . 4 c > - attention 88 . 4 c > - attention 88 . 4 cap > table 3 : effect of removing sense priors and context sensitivity ( attention ) from the model .
< extra_id_0 > en - de c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > en - de c > en - de c > flickr16 c > mscoco17 c > mscoco17 c > en - de c > en - de c > en - de c > en - de c >
< extra_id_0 > mscoco17 c > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c >
< extra_id_0 > 32 . 0 c > 28 . 7 c > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > en - fr c > en - fr c > mscoco17 c > mscoco17 c > mscoco
< extra_id_0 > mscoco17 c > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > enc - gate
< extra_id_0 > en - fr c > flickr16 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c >
< extra_id_0 > en - fr - trans - ff and en - fr - smt - back perform better than en - fr - trans - ff and en - fr - trans - back , respectively . mtld performs better than en - fr - trans - ff and en - fr - trans - back , respectively .
< extra_id_0 > c > language pair c > train c > test c > dev c > en – fr c > 1 , 472 , 203 c > 4 , 99 , 487 c > 5 , 734 cap > table 1 : number of parallel sentences in the train , test and development splits for the language pairs we used .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . r > c > en – fr c > 113 , 132 c > 131 , 104 c > en – es c > 168 , 195 cap > table 2 : training vocabularies for the english , french and spanish data used for our models .
< extra_id_0 > c > en - fr - rnn - rev c > 33 . 3 c > 50 . 2 c > en - fr - trans - rev c > 36 . 5 c > 47 . 1 c > en - fr - trans - rev c > [ bold ] 40 . 4 c > [ bold ] 42 . 7 c > [ bold ] 42 . 7 c > en - fr - trans - rev
< extra_id_0 > recall @ 10 ( % ) c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empt
< extra_id_0 > recall @ 10 ( % ) c > [ empty ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c
< extra_id_0 > turns in a u > screenplay that u > at the edges ; it ’ s so clever you want hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate
< extra_id_0 > 1 c > + 12 c > + 12 c > + 12 c > 1 c > + 12 c > 1 c > + 12 c > 1 c > + 12 c > 1 c > + 12 c > 1 c > + 12 c > 1 c > 1 c > 1 c > 1
< extra_id_0 > bold > rnn / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold
< extra_id_0 > bold > sst - 2 / bold > bold > pubmed / bold > bold > pmi / bold > bold > sst - 2 / bold > bold > pmi / bold > bold > pmi / bold > bold > pmi / bold > bold > pmi / bold > bold > pmi / bold >
