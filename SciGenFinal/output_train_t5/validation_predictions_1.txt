< extra_id_0 > ( instances / s ) inference c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > through
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness .
< extra_id_0 > c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters activation func . c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters
< extra_id_0 > [ bold ] relation ( in 5 - fold ) without sdp c > [ bold ] relation ( in 5 - fold ) without sdp c > [ bold ] relation ( in 5 - fold ) without sdp c > [ bold ] relation ( in 5 - fold ) without sdp c > [ bold ] relation ( in 5 - fold ) without sdp c > [ bold ] relation ( in 5 - fold ) without sdp
< extra_id_0 > 100 % c > c - f1 100 % c > r - f1 100 % c > r - f1 50 % c > r - f1 100 % c > r - f1 50 % c > r - f1 100 % c > r - f1 50 % c > r - f1 100 % c > r - f1 100 % c > r - f1 100 % c > r - f1 100 % c > r - f1 100 % c
< extra_id_0 > r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c
c > lstm - parser c > 60 . 623 . 54 c > 9 . 4013 . 57 r > c > paragraph c > 64 . 741 . 97 c > 56 . 242 . 87 cap > table 4 : c - f1 ( 100 % ) for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the runs given in table 2 .
< extra_id_0 > c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c >
< extra_id_0 > ser ( % ) r > c > [ bold ] dataset c > [ bold ] mrs c > [ bold ] ser ( % ) r > c > [ 0 . 5pt / 2pt ] cleaned c > train c > 8 , 362 c > 42 , 061 c > 17 . 69 r > c > [ 0 . 5pt / 2pt ] cleaned c > test c >
< extra_id_0 > test c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c > [ bold ] system c
< extra_id_0 > [ bold ] training data c > [ bold ] miss c > [ bold ] wrong c > [ bold ] disfl r > c > table 4 : results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) .
< extra_id_0 > b r > c > [ bold ] model c > b r > c > [ bold ] model c > b r > c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ]
< extra_id_0 > gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . # p shows the model size in terms
< extra_id_0 > english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german # p
< extra_id_0 > c > [ italic ] block c > [ italic ] block c > [ italic ] block c > [ italic ] block c > [ italic ] block c > [ italic ] block c > [ italic ] block c > [ italic ] block c > [ italic ] block c > [ italic ] block c > [ italic ] block c > [ italic ] block c >
< extra_id_0 > rc + la ( 2 ) c > b 16 . 8 c > c 48 . 1 c > [ bold ] gcn + rc + la ( 2 ) c > [ bold ] gcn + rc + la ( 2 ) c > b 16 . 8 c > c 47 . 9 r > c > [ bold ] gcn + rc + la ( 2 ) c > b 18 . 3 c > c 47 . 9 r > c > + rc + la ( 2 )
< extra_id_0 > c > [ bold ] 22 . 2 c > [ bold ] 52 . 0 r > c > [ bold ] 52 . 3 r > c > [ bold ] 52 . 3 r > c > [ bold ] 53 . 4 r > c > [ bold ] 54 . 4 r > c > [ bold ] 54 . 4 r > c > [ bold ] 54 . 4 r > c > [ b
r > c > [ bold ] model c > b c > c r > c > dcgcn4 c > 25 . 5 c > 55 . 4 r > c > - 4 dense blocks c > 23 . 8 c > 54 . 1 r > c > - 2 , 3 , 4 dense blocks c > 23 . 2 c > 53 . 1 cap > table 8 : ablation study
< extra_id_0 > table 9 : ablation study for modules used in the graph encoder and the lstm decoder . table 9 : ablation study for modules used in the graph encoder and the lstm decoder . table 9 : ablation study for modules used in the graph encoder and the lstm decoder . table 9 : ablation study for modules used in the graph encoder and the lstm decoder . table 9 : ablation study for modules used in the graph encoder and the lstm de
< extra_id_0 > initialization c > depth c > objnum c > tense c > objnum c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst
< extra_id_0 > depth c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topcon
< extra_id_0 > c > [ bold ] 79 . 2 c > [ bold ] 79 . 2 c > [ bold ] 74 . 0 c > [ bold ] 74 . 0 c > [ bold ] 74 . 0 c > [ bold ] 74 . 0 c > [ bold ] 74 . 0 c > [ bold ] 74 . 0 c > [ bold ] 74 . 0 c > [ bold ] 74 . 0 c > [ bold ]
< extra_id_0 > method c > sts12 c > sts13 c > sts14 c > sts15 c > sts16 r > c > method c > method c > method c > method c > method c > method c > method c > method c > method c > method c > method c > method c > method c > method
< extra_id_0 > c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 77 . 2 c > [ bold ] 77 . 2 c > [ bold ] 77 . 2 c > [ bold ] 77 . 2 c > [ bold ] 77 . 2 c > [ bold ] 77 . 2 c > [ bold ] 77 . 2 c > [ bold ] 77 . 2
< extra_id_0 > method c > sts12 c > sts13 c > sts14 c > sts15 c > sts16 r > c > method c > sts12 c > sts13 c > sts14 c > sts15 c > sts16 r > c > method c > sts15 c > sts16 r > c > method
< extra_id_0 > c > wc r > c > wc r > c > cmow - c c > [ bold ] 36 . 2 c > [ bold ] 66 . 0 c > 78 . 7 c > 78 . 7 c > 78 . 7 c > 79 . 8 c > [ bold ] 79 . 8 c > [ bold ] 79 . 8 c > [ bold
< extra_id_0 > c > cmow - r c > [ bold ] 87 . 5 c > [ bold ] 74 . 6 c > [ bold ] 74 . 6 c > [ bold ] 74 . 6 c > [ bold ] 74 . 6 c > [ bold ] 74 . 6 c > [ bold ] 74 . 6 c > [ bold ] 74 . 6 c > [ bold ] 74 . 6 c > [ bold ] 74 . 6 c
< extra_id_0 > loc c > in [ italic ] e + org c > in [ italic ] e + misc c > in [ italic ] e + org c > in [ italic ] e + misc c > in [ italic ] e + misc c > in [ italic ] e + org c > in [ italic ] e + misc c > in [ italic ] e + misc c > in [
< extra_id_0 > 87 0 . 72 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87 c > 35 . 87
< extra_id_0 > gen ref gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen
< extra_id_0 > > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > c > - r
< extra_id_0 > c > bold > model / bold > c > bold > bleu / bold > c > song et al . ( 2018 ) c > 200k c > 27 . 40 r > c > song et al . ( 2018 ) c > 200k c > 28 . 20 r > c > guo et al . ( 2019 ) c > 200k c > 31
< extra_id_0 > > bold > bleu / bold > c > bold > meteor / bold > c > bold > size / bold > c > bold > meteor / bold > c > bold > meteor / bold > c > bold > size / bold > c > 57 . 6m r > c
< extra_id_0 > / bold > 0 - 7 c > bold > graph diameter / bold > 7 - 13 c > bold > graph diameter / bold > 0 - 7 c > bold > graph diameter / bold > 7 - 13 c > bold > graph diameter / bold > 7 - 13 c > bold > graph diameter / bold > 14 - 20 r >
< extra_id_0 > bold > model / bold > c > bold > miss / bold > c > bold > added / bold > c > bold > miss / bold > r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c >
< extra_id_0 > r > c > [ empty ] c > ar c > es c > fr c > ru c > zh c > en r > c > pos c > 88 . 7 c > 90 . 0 c > 89 . 6 c > 88 . 4 c > 87 . 4 c > sem c > 85 . 3 c > 86 . 1
< extra_id_0 > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty
< extra_id_0 > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr
< extra_id_0 > table 5 : pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . table 5 : pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual encoders , averaged over all non - english target languages .
< extra_id_0 > task c > protected attribute c > dial c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c
< extra_id_0 > task c > accuracy r > c > dial c > sentiment c > 67 . 4 r > c > [ italic ] race c > 81 . 2 r > c > sentiment c > 67 . 4 r > c > [ empty ] c > [ italic ] gender c > 67 . 4 r > c > [ ita
< extra_id_0 > table 2 : protected attribute leakage : balanced & unbalanced data splits . r > c > dial c > sentiment c > race c > 67 . 4 c > 64 . 5 c > 79 . 5 c > 73 . 5 r > c > [ empty ] c > age c > 74 . 7 c > 59 . 4 c > 77 . 5 c >
< extra_id_0 > task acc c > leakage c > r > c > dial c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c >
< extra_id_0 > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > embedding leaky c > 64 . 5 c > 67 . 8 r > c > rnn c > guarded c > 59 . 3 c > 54 . 8 cap > table 6 : accuracies of the protected
< extra_id_0 > ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al .
< extra_id_0 > # params c > model c > # params c > model c > # params c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model
< extra_id_0 > # params c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c
r > c > model c > # params c > bleu c > train c > decode c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c
< extra_id_0 > “ # params ” : the parameter number of base . “ # params ” : the parameter number of elmo . “ # params ” : the parameter number of base . “ # params ” : the parameter number of base . “ # params ” : the parameter number of model . “ # params ” : the parameter number of base .
< extra_id_0 > “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task . “ # params ” : the parameter number .
< extra_id_0 > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting . table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting .
< extra_id_0 > w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # word c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ]
< extra_id_0 > top - 1 / 2 : % of evaluations a system being ( best ) . top - 1 / 2 : % of evaluations a system being ( best ) . top - 1 / 2 : % of evaluations a system being ( best ) . top - 1 / 2 : % of evaluations a system being ( best ) . top - 1 / 2 : % of evaluations a system being ( best ) . top - 1 / 2 : % of evaluations a system being ( best ) . top - 1 / 2 :
< extra_id_0 > dsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim
< extra_id_0 > dsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim
< extra_id_0 > dsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim c > dlqsim
< extra_id_0 > 957 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 r > r > c > europarl c > totalroots : c > 999 r > r > c > europarl c > maxdepth : c > 1182 c > 11 .
< extra_id_0 > 980 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 r > r > c > europarl c > maxdepth : c > 980 c > 980 c > 984 c > 894 c > 884 c > 849 c > 980 c > 980 c > 980 c > 980
< extra_id_0 > table 1 : performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . table 1 : performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned . lf is the enhanced version as we mentioned .
< extra_id_0 > table 2 : performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . p1 indicates the most effective one ( i . e . , hidden dictionary learning ) . p2 indicates the most effective one ( i . e . , hidden dictionary learning ) shown in table 2 .
< extra_id_0 > lv - en c > lv - en c > lv - en c > lv - en r > c > lv - en r > c > lv - en r > c > lv - en r > c > lv - en r > c > lv - en r > c > lv - en
< extra_id_0 > / bold > zh - en c > bold > direct assessment / bold > lv - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > ru - en c > bold > direct assessment / bold > tr - en c > bold > direct assessment / bold > lv
< extra_id_0 > > qual / bold > c > bagel bold > inf / bold > c > bagel bold > qual / bold > c > bagel bold > qual / bold > c > bagel bold > qual / bold > c > bagel bold > qual / bold > c > bagel
< extra_id_0 > / bold > r > c > setting c > metric c > m1 c > m2 r > c > setting c > metric c > m1 c > m2 r > c > baselines c > leic ( * ) c > meteor ( * ) c > meteor ( * ) c > meteor ( * ) c > me
< extra_id_0 > 0 . 728 c > 63 . 2 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 r >
< extra_id_0 > b c > models a c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models
acc c > % of machine and human judgments that match c > 94 c > 84 r > c > acc c > % of machine and human judgments that match c > 94 c > 84 r > c > acc c > % of machine and human judgments that match c > 0 . 79 c > 0 . 75 r > c > 0 . 67 cap
< extra_id_0 > 0 . 719 c > 37 . 3 c > 37 . 3 c > 10 . 0 r > c > [ empty ] c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c
< extra_id_0 > bleu . acc : bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . acc : acc : bleu is between 1000 transferred sentences and human references , and bleu is between 1000 transferred sentences and human references . acc : bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . acc : bleu is between 1000 transferred sentences and human references . acc :
< extra_id_0 > r > c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type
r > c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type
< extra_id_0 > c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ]
< extra_id_0 > disagree c > accuracy ( % ) unrelated c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > accuracy ( % ) unrelated c > accuracy ( % ) unrelated c > accuracy ( % ) unrelated c > accuracy ( % ) unrelated c > accuracy ( % ) unrelated c > accuracy ( % ) unrelated c > accuracy ( % ) unrelated
< extra_id_0 > table 2 : accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . table 2 : accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) .
< extra_id_0 > table 3 : accuracy ( % ) comparisons of component models with and without attention . table 3 : accuracy ( % ) comparisons of component models with and without attention .
< extra_id_0 > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ]
< extra_id_0 > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ]
< extra_id_0 > acc c > test perp c > test wer c > test perp c > test wer r > c > test wer r > c > test wer c > test wer c > test wer c > test wer c > test wer c > test wer c > test wer c > test wer c > test wer c >
< extra_id_0 > train dev c > 25 % train test c > 50 % train dev c > 50 % train test c > 75 % train dev c > 75 % train test c > full train dev c > full train test c > full train dev c > full train dev c > full train test c > full train dev c > full train test c > full train dev c > full train test
c > dev cs c > test mono c > test mono c > test mono c > test mono c > test mono c > test mono c > test mono c > test mono c > test mono c > test mono c > test mono
< extra_id_0 > precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) .
< extra_id_0 > c > [ bold ] conll - 2003 c > [ bold ] p c > [ bold ] r c > [ bold ] f r > c > baseline c > 93 . 89 c > 94 . 16 c > 94 . 03 c > [ bold ] f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant
< extra_id_0 > hpcd ( full ) is from the original paper , and it uses syntactic skipgram . glove - retro is glove vectors retrofitted to wordnet 3 . 1 , and glove - extended refers to the synset embeddings obtained by running autoextend rothe and schütze ( 2015 ) on glove .
< extra_id_0 > [ bold ] full uas c > [ bold ] full uas c > [ bold ] ppa acc . r > c > [ bold ] full uas c > [ bold ] full uas c > [ bold ] full uas c > [ bold ] ppa acc . r > c > rbg c > 94 . 17 c > 88 . 51 r >
r > c > [ bold ] ppa acc . r > c > - sense priors c > 88 . 4 r > c > - attention c > 87 . 5 cap > table 3 : effect of removing sense priors and context sensitivity ( attention ) from the model .
< extra_id_0 > en - de c > flickr16 c > flickr17 c > mscoco17 r > c > multi30k c > 61 . 4 c > 54 . 0 c > 43 . 1 r > c > + subsfull c > 53 . 7 c > 48 . 9 c > 47 . 0 r > c > + ensemble - of - 3 c > [ bold ] 51 . 7
< extra_id_0 > en - de c > flickr16 c > flickr17 c > mscoco17 r > c > a c > subs1m [ italic ] [ italic ] h + ms - coco c > 66 . 3 c > 60 . 5 c > 60 . 5 c > 52 . 1 r > c > a c > subs1m [ italic ] [ italic ] h + ms - co
< extra_id_0 > table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table
< extra_id_0 > mscoco17 r > c > en - de c > flickr16 c > flickr17 c > mscoco17 r > c > en - fr c > flickr17 c > mscoco17 r > c > en - de c > flickr16 c > flickr17 c > mscoco17 r > c >
< extra_id_0 > mscoco17 c > flickr16 c > flickr17 c > flickr17 c > mscoco17 r > c > en - fr c > flickr16 c > flickr17 c > flickr17 c > mscoco17 r > c > en - fr c > en - fr c > en - fr c
< extra_id_0 > c > mtld c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation c > translation
r > c > language pair c > train c > test c > dev r > c > en – fr c > 1 , 472 , 203 c > 459 , 633 c > 5 , 734 cap > table 1 : number of parallel sentences in the train , test and development splits for the language pairs we used . table 2 : number of parallel sentences in the train , test and development splits for the language pairs we used .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . table 2 : training vocabularies for the english , french and spanish data used for our models . table 2 : training vocabularies for the english , french and spanish data used for our models .
< extra_id_0 > r > c > system reference c > bleu c > ter r > c > system reference c > en - fr - trans - rev c > 33 . 3 c > 50 . 2 r > c > en - fr - trans - rev c > 36 . 5 c > 47 . 1 r > c > en - fr - trans - rev c
< extra_id_0 > c > [ empty ] c > recall @ 10 ( % ) c > median rank c > rsaimage r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c
< extra_id_0 > recall @ 10 ( % ) c > median rank c > rsaimage r > c > [ empty ] c > recall @ 10 ( % ) c > median rank c > rsaimage r > c > [ empty ] c > recall @ 10 ( % ) c > median rank c > rsaimage r > c > vgs c > 27 c
u > turns in a u > screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screen
< extra_id_0 > r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > c > bold > rnn / bold > c > bold > dan / bold > c > bold > dan / bold > c > bold > dan / bold > r > c > sentiment score changes in sst - 2 . the numbers indicate the changes in percentage points with respect to the original sentence .
< extra_id_0 > objective c > bold > pubmed / bold > objective c > bold > pubmed / bold > objective c > bold > pubmed / bold > objective c > bold > pubmed / bold > objective c > bold > pubmed / bold > objective c > bold > pmi / bold >
