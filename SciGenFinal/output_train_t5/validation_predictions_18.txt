< extra_id_0 > training c > throughput ( instances / s ) inference c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 .
< extra_id_0 > the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations with different representation . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) with sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > + 27 . 82 c > + 27 . 82 c > + 27 . 82 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > c - f1 100 % c - f1 50 % c - f1 100 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c
< extra_id_0 > paragraph level acc . c > paragraph level c - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c >
< extra_id_0 > c > [ empty ] c > lstm - parser c > lstm - parser c > essay vs . paragraph level ; c - f1 ( 100 % ) in % for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the runs given in table 2 .
< extra_id_0 > train c > test c > train c > train c > test c > train c > train c > test c > train c > train c > train c > test c > train c > train c > test c > train c > train c > test c > train c > test c > train c > test c > train c > test c > test c > test c > test c > test c > test c > train c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test c > test cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cide
< extra_id_0 > cap > table 1 : data statistics comparison for the original e2e data and our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by our slot matching script , see section 3 ) .
< extra_id_0 > bleu c > < extra_id_1 > train c > test c > nist c > original c > original c > original c > original c > original c > original c > original c > original c > tleu c > tleu c > tleu c > tleu c > tleu c > tleu c > tleu c > tleu c >
< extra_id_0 > table 4 : results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies , slight disfluencies ) .
< extra_id_0 > graphlstm ( song et al . , 2018 ) and gcnseq ( damonte and cohen , 2019 ) have the best performance . graphlstm ( song et al . , 2018 ) has a better performance than snrg ( song et al . , 2017 ) and tree2str ( song et al . , 2017 ) have a better performance . graphlstm has a better performance than snrg ( song et al . , 2018 ) has a better performance .
< extra_id_0 > the model size in terms of parameters . gcnseq achieves 24 . 5 bleu points . gcnseq achieves 24 . 5 bleu points . ggnn2seq achieves 24 . 5 bleu points . ggnn2seq achieves 24 . 5 bleu points .
< extra_id_0 > english - czech b c > [ bold ] english - czech b c > [ bold ] english - czech b c > [ bold ] english - czech b c > [ bold ] english - czech b c > [ bold ] english - czech b c > [ bold ] english - czech b c > [ bold ] english - german b c > [ bold ] english - german c
< extra_id_0 > 48 . 3 compared to c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > gcn + rc ( 2 ) has b 16 . 8 and c 48 . 1 respectively . gcn + rc + la ( 2 ) has b 16 . 8 and c 47 . 9 respectively . compared to baselines , gcn + rc + la ( 2 ) has b 16 . 8 and c 47 . 9 respectively . compared to baselines , gcn + rc + la ( 2 ) has b 18 . 3 and c 47 . 9 respectively . compared to baselines , gcn + rc ( 4 ) and + rc + la ( 2 ) have a better performance than dcgcn3 ( 27 ) and dcgcn4 ( 36 ) has a better performance .
< extra_id_0 > compared to dcgcn ( 2 ) and dcgcn ( 4 ) , which have significantly higher performance than dcgcn ( 3 ) and dcgcn ( 4 ) , which have significantly higher performance than dcgcn ( 4 ) and dcgcn ( 4 ) , which have significantly higher performance than dcgcn ( 4 ) and dcgcn ( 4 ) , which have significantly higher performance than dcgcn ( 4 ) and dcgcn ( 4 ) , which have significantly higher performance than dcgcn ( 4 ) and dcgcn ( 4 ) , which have significantly higher performance than dcgcn ( 4 ) and dcgcn ( 4 ) , which have significantly higher performance , respectively .
< extra_id_0 > table 8 : ablation study for dense connections on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > table 9 : ablation study for modules used in the dcgcn4 encoder and the lstm decoder . the lstm encoder and lstm decoder perform better than the encoder and lstm decoder in terms of coverage mechanism .
< extra_id_0 > initialization c > depth c > objnum c > tense c > coordinv c > topconst c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > 78 . 9 c > 78 . 7 c > 79 . 2 c > [ bold ] 70 . 7 c > [ bold ] 70 . 7 c > [ bold ] 70 . 7 c > [ bold ] 70 . 7 c > [ bold ] 79 . 2 c > [ bold ] 70 . 7 c > [ bold ] 70 . 7 c > [ bold ] 70 . 7 c > [ bold ] 70 . 7 c > [ bshif
< extra_id_0 > 79 . 2 compared to 79 . 9 for mrpc and 79 . 9 for sick - e and 79 . 9 for sick - r . compared to cmow / 784 and cmow / 784 , hybrid achieves 79 . 2 compared to 79 . 9 for sick - e and 79 . 9 for sick - r . compared to cmow / 784 and cmow / 784 , hybrid achieves 79 . 2 compared to 79 . 9 compared to 79 . 9 for sick - r .
< extra_id_0 > c > sts14 c > sts14 c > sts16 c > sts16 c > sts16 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp > cmp .
< extra_id_0 > 6 % compared to the baseline of our paper and our initialization of subj and mpqa . mrpc and mrpc perform better than glorot and sick - e and sick - r , respectively . our paper performs better than glorot and sick - r and sick - r .
< extra_id_0 > c > sts14 c > sts15 c > sts16 c > cmow - c c > [ bold ] 31 . 9 c > [ bold ] 31 . 9 c > [ bold ] 43 . 5 c > [ bold ] 52 . 2 c > [ bold ] 61 . 0 c > [ bold ] 61 . 0 c > [ bold ] 61 . 0 c > [ bold ] 61 . 0 c > [ cbow - c c > c > c > c > [ bold - c c > [ bold ] c > [ bold ] c > [ bold ] c > [ cbow - r c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold
< extra_id_0 > compared to cmow - c and cmow - r , respectively . cmow - r performs better than cmow - r and cmow - r , respectively . cmow - r performs better than cmow - r and cmow - r , respectively . cmow - r performs better than cmow - r and cmow - r , respectively . cmow - r performs better than cmow - r and cmow - r .
< extra_id_0 > mrpc and mrpc perform better than sick - e and sick - r . cmow - r performs better than sick - e and sick - b . cmow - r performs better than sick - e and sick - b . cmow - r performs better than sick - e and sick - b . cmow - r performs better than sick - e and sick - b .
< extra_id_0 > all org c > all misc c > all misc c > all loc c > all org c > all misc c > all org c > all misc c > all misc c > mil - nd c > 96 . 26 c > 89 . 48 c > 89 . 46 c > 89 . 46 c > 89 . 46 c > 89 . 46 c >
< extra_id_0 > . in [ italic ] e + p c > all r c > all f1 c > 69 . 38 c > 69 . 38 0 . 68 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c >
< extra_id_0 > gen bold > ent / bold > c > gen ref gen bold > neu / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > g2s - gin c > 22 . 55 0 . 17 0 . 16 0 . 16 0 . 16 0 . 16 0 . 16 c > bold > bold > g2s - ggnn c > damonte et al . ( 2018 ) c > damonte et al . ( 2018 ) c >
< extra_id_0 > bold > model / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold >
< extra_id_0 > bold > meteor / bold > bold > size / bold > c > 57 . 6m c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > 0 - 7
< extra_id_0 > table 8 shows the fraction of elements in the output that are missing in the generated sentence ( added ) and the fraction of elements in the input that are missing in the generated sentence ( miss ) for the test set of ldc2017t10 . the token lemmas are used in the comparison .
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer .
< extra_id_0 > table 2 shows the pos and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy are shown in table 2 .
< extra_id_0 > fr c > zh c > fr c > fr c > zh c > en c > en c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > pos tagging accuracy c > 87 . 9 c > 89 . 4
< extra_id_0 > 2 91 . 7 c > 3 91 . 8 c > 4 91 . 9 c > uni c > pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages , in table 5 .
< extra_id_0 > task c > sentiment c > sentiment c > sentiment c > mention c > sentiment c > mention c > sentiment c > mention c > mention c > mention c > gender c > 9 . 7 cap > attacker ’ s performance on different datasets . results are on a training set 10 % held - out . is the difference between the attacker
< extra_id_0 > task c > accuracy c > 67 . 4 c > mention c > 67 . 4 c > sentiment c > 67 . 4 c > mention c > 67 . 4 c > mention c > 67 . 4 c > mention c > 64 . 8 c > mention c > 67 . 4 c > mention c > 67 . 4 c >
< extra_id_0 > data c > dial c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment
< extra_id_0 > data c > task acc c > leakage c > 5 . 0 on different datasets with an adversarial training . is the difference between the attacker score and the adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy .
< extra_id_0 > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > embedding leaky c > 67 . 8 c > embedding guarded c > 59 . 3 c > 54 . 8 cap > accuracies of the protected attribute with different encoders .
< extra_id_0 > 40 . 68 < extra_id_1 > ptb + finetune c > wt2 base c > wt2 + dynamic c > yang et al . ( 2018 ) compared the results of yang et al . ( 2018 ) and yang et al . ( 2018 ) compared the results of yang et al . ( 2018 ) and yang et al . ( 2018 ) compared the results of yang et al . ( 2018 c >
< extra_id_0 > base time c > + bert acc c > + bert time c > + ln acc c > + bert time c > + ln + bert time c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > amapolar time c > yahoo err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > zhang et al . ( 2015 ) c >
< extra_id_0 > model c > # params c > train c > decode c > train c > train c > decode c > train c > train c > decode c > train c > decode c > train c > decode c > decode c > decode c > decode c > decode c > decode c > decode c > decode
< extra_id_0 > model c > + elmo c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c > - c >
< extra_id_0 > table 6 shows the f1 score on conll - 2003 english ner task . lstm * denotes the parameter number in ner task . lstm * denotes the reported result .
< extra_id_0 > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting and test perplexity on snli task with base + ln setting . ptb task with base + ln setting and snli task with base setting .
< extra_id_0 > r - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] r - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] r - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] c > [ italic ] c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] c > 66 c > 22 c > 22 c > 22 c > 22 c > 22 c > 22 c > 22 c > 66 c > 22 c > 66 c > 22 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2 c > 2
< extra_id_0 > the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is 1 . 0 , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold .
< extra_id_0 > 0443 and 0 . 0761 respectively . in terms of p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p
< extra_id_0 > 0 . 0083 and 0 . 0092 respectively . dsim and docsub perform better than df and hlqs in terms of p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c >
< extra_id_0 > 0490 and 0 . 0613 respectively . dsim and docsub perform better than df and hlqs in terms of p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c >
< extra_id_0 > slqs and docsub perform better than corpus c > dsim and docsub c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c >
< extra_id_0 > slqs and docsub perform better than corpus c > dsim c > docsub c > hclust c > europarl c > totalroots : c > 980 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 c > 1 , 000 cluster clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust c
< extra_id_0 > table 1 shows the performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 .
< extra_id_0 > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > p2 c > 71 . 88 c >
< extra_id_0 > fi - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > cs - en and zh - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > lv - en c > bold > direct assessment / bold > zh - en c > bertscore - f1 c > 0 . 652 c > 0 . 646 c > 0 . 646 c > 0 . 646 c > c > c > c > c > c > c > c > c > c > c > c > c > / bold > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > . < extra_id_1 > > < extra_id_2 > bold > qual / bold > sfhotel bold > qual / bold > c > sfhotel bold > qual / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > and m2 respectively . for m1 and m2 , we observe that leic ( * ) scores significantly better than spice ( * ) and bertscore - recall ( * ) scores better than spice ( * ) and bertscore - recall ( * ) scores better than spice ( * ) and bertscore - recall ( * ) scores better than spice ( * ) and bertscore - recall ( * ) scores better than spice ( * ) and bertscore - recall ( * ) score better than spice ( * ) scores better than spice scores better than spice scores better than spice scores .
< extra_id_0 > 0 . 728 c > 8 . 81 c > gm c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m1 : m0 [ italic ] + para c > m4 : m0 [ italic ] c > m4 : m0 [ italic ] c > m4 : m0 [ italic ] c > m4 : m0 [ italic ] c > m4 : m0 [ italic ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > transfer quality a > b > a > b > transfer quality tie sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r
< extra_id_0 > c > metric c > human sentence - level validation of metrics ; 150 examples for sim and pp ; 150 for spearman ’ s [ italic ] and 150 for spearman ’ s [ italic ] and 150 for spearman ’ s [ italic ] and 150 for spearman ’ s [ italic ] and 150 for spearman ’ s [ italic ] and 150 for spearman ’ s [ italic ] and 150 for pp ; see text for validation of gm .
< extra_id_0 > shen - 1 and cyc + 2d have significantly better performance than m0 and cyc + 2d , respectively . compared to m0 and m7 , the results show that cyc + para and cyc + 2d have significantly better performance than the m1 and m5 models . compared to the m5 model , cyc + para and cyc + 2d have significantly better performance .
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work at similar levels of acc , but untransferred sentences achieve the highest bleu than prior work at similar levels of bleu . bleu is between 1000 transferred sentences and human references , and bleu is between 1000 transferred sentences and human references . our best models achieve higher bleu than previous work at similar levels of acc .
< extra_id_0 > reparandum length [ bold ] 3 - 5 c > reparandum length [ bold ] 3 - 5 c > reparandum length [ bold ] 3 - 5 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 1 c > 1 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c
< extra_id_0 > table 3 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both the reparandum and repair ( content - content ) , either the reparandum or repair ( content - function ) or in neither . the proportion of tokens belong to each category is shown in table 3 .
< extra_id_0 > [ bold ] dev mean c > [ bold ] dev best c > [ italic ] c > [ empty ] c > [ bold ] dev mean c > [ bold ] dev best c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – – –
< extra_id_0 > ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > performance comparison with the state - of - art algorithms on the fnc - 1 test dataset . our model performs better than the state - of - art algorithms on the fnc - 1 test dataset .
< extra_id_0 > the unified model significantly outperforms all previous models on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models .
< extra_id_0 > table 3 shows the accuracy ( % ) comparisons of component models with and without attention . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > [ bold ] 1 / 1 and 1 / n . we observe that embedding + t and embedding + t perform better than embedding + t and embedding + t and embedding + t and embedding + t and embedding + t and embedding + t perform better than embedding + t and embedding + t and embedding + t and embedding + t and embedding + t perform better than the other models perform better than cnn performs better than cnn performs better than cnn performs better than embedding + t perform better than embedding + t and embedding + t and embedding + t .
< extra_id_0 > trigger [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ) classification ( % ) c > [ bold ] identification ( bold ) c > [ bold ) c > [ bold ] f1 c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ]
< extra_id_0 > dev wer
< extra_id_0 > train dev c > 50 % train test c > 50 % train test c > 75 % train dev c > 75 % train test c > cs - only c > 68 . 4 c > cs - only c > 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > c > c > c > c > c > c > c > c > c > c > c > c > c > cs - only c > c > c > cs - only c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c >
< extra_id_0 > table 5 shows the accuracy on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . using type - aggregated gaze features trained on all three eye - tracking datasets is shown in table 7 .
< extra_id_0 > table 5 shows the performance of type - aggregated gaze features on the conll - 2003 dataset ( p , r , f1 - score , f1 - score , f1 - score , p , f1 - score , f1 - score , f1 - score , p , r , f1 - score , f1 - score , p , r , f1 - score , f1 - score , p , f1 - score , p , r , f1 - score , f1 scores for type - aggregated gaze features on conll - 2003 dataset ( p , f , f , f1 - score , p , p , f , p , p , f , p , f , p , f , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , p , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll - 2003 , conll
< extra_id_0 > table 1 summarizes the results on belinkov2014exploring ’ s ppa test set . lstm - pp and lstm - pp perform better than glove - retro and glove - extended , respectively .
< extra_id_0 > table 2 summarizes results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachment predictors . rbg + hpcd ( full ) achieves 94 . 17 and 88 . 51 , respectively .
< extra_id_0 > table 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the ppa acc . the effect of removing sense priors and context sensitivity ( attention ) from the model is shown in table 3 .
< extra_id_0 > c > en - de c > flickr16 c > mscoco17 c > mscoco17 c > en - fr c > en - de c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > en - de c > en - de c > en - de c > en - de
< extra_id_0 > and mscoco17 , respectively . the results show that subs1m [ italic ] h + ms - coco outperforms subs1m [ italic ] [ italic ] lm + ms - coco and lm + ms - coco , respectively , and lm + ms - coco outperforms subs1m [ italic ] [ italic ] [ italic ] lm + ms - coco and lm + ms - coco , respectively , and lm + ms - cococo , respectively .
< extra_id_0 > autocap 1 - 5 ( concat ) and autocap ( dual attn . ) have significantly better performance than autocap 1 - 5 ( concat ) and autocap ( dual attn . ) on flickr16 and mscoco17 . adding automatic image captions to flickr16 and mscoco17 improves the performance of en - de and mscoco17 . adding automatic image captions to flickr16 and mscoco17 improves the performance of en - fr
< extra_id_0 > mscoco17 and en - de c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > [ bold ] c > c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > enc - gate c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > 68 .
< extra_id_0 > mscoco17 and en - fr c > flickr16 c > mscoco17 c > mscoco17 c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > mscoco17 c > mscoco17 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > 8656 and 109 . 8842 respectively . mtld and en - fr - trans - ff perform better than en - fr - trans - back and en - fr - trans - back , respectively . mtld and en - fr - trans - back perform better than en - fr - trans - back and en - fr - trans - back , respectively .
< extra_id_0 > table 1 : number of parallel sentences in the train , test and development splits for the language pairs we used . en – fr has a total of 1 , 467 , 489 parallel sentences in the train , test and development splits .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . the training vocabularies for the english , french and spanish data used for our models are shown in table 2 .
< extra_id_0 > table 5 shows the automatic evaluation scores ( bleu and ter ) for the rev systems . the bleu and ter scores ( en - fr - rnn - rev and en - fr - trans - rev ) are shown in table 5 .
< extra_id_0 > recall @ 10 ( % ) c > [ empty ] c > recall @ 10 ( % ) c > median rank c > 0 . 2 c > rsaimage c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c >
< extra_id_0 > recall @ 10 ( % ) c > rsaimage c > 0 . 4 c > chance c > 0 c > 3 , 955 c > 0 . 0 c > chance c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c >
< extra_id_0 > she turns in a u > screenplay that u > at the edges edges edges curves so clever easy want hate hate hate hate hate hate hate hate hate hate . we report further examples of the different classifiers in table 1 .
< extra_id_0 > < extra_id_1 > bold > rnn / bold > 3 cnn / bold > 4 cnn / bold > 4 cnn / bold > 4 cnn / bold > 4 cnn / bold > 4 cnn / bold > 4 cnn / bold > 4 cnn / bold > 4 cnn / bold >
< extra_id_0 > bold > rnn / bold > bold > dan / bold > bold > dan / bold > table 3 : sentiment score changes in sst - 2 . the numbers indicate that the score increases in positive and negative sentiment .
< extra_id_0 > better than sst - 2 and pubmed / bold > . compared with pmi and pubmed / bold > , there is a significant difference between the best and the bad . compared to pmi and pubmed / bold > , there is a significant difference between the best and the bad . compared to sst - 2 and pubmed / bold > , there is a significant difference between the best and the bad . compared to sst - 2 and pmi , there is a significant difference between the best .
