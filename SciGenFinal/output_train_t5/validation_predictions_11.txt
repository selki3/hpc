< extra_id_0 > training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c > throughput ( instances / s ) training c >
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but the linear dataset exhibits only a small room of improvement .
< extra_id_0 > the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations with different representation . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) with sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) with sdp c > + 19 . 90 c >
< extra_id_0 > f1 100 % c - f1 50 % c - f1 100 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c >
< extra_id_0 > paragraph level acc . c > paragraph level c - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c >
< extra_id_0 > c > [ empty ] c > lstm - parser c > [ empty ] c > lstm - parser c > [ empty ] c > lstm - parser c > [ empty ] c > [ empty ] c > [ empty ] c > lstm - parser c > [ empty ] c > [ empt
< extra_id_0 > bleu c > [ bold ] train c > [ bold ] test c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold train
< extra_id_0 > mrs c > [ bold ] part c > [ bold ] refs c > [ bold ] refs c > [ bold ] ser ( % ) c > ( 0 . 00 ) c > [ 0 . 5pt / 2pt ] cleaned c > train c > 1 , 358 c > 4 , 693 c > ( 0 . 00 ) c > [ 0 . 5pt / 2pt ] cleaned c > train c > ( 0 . 00 ) c > ( 0 . 00 ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % ) ser ( % )
< extra_id_0 > bleu cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cide
< extra_id_0 > table 4 : results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies , slight disfluencies ) .
< extra_id_0 > 22 . 0 c > graphlstm ( song et al . , 2018 ) and tree2str ( song et al . , 2018 ) c > - c > 24 . 4 c > gcnseq ( damonte and cohen , 2019 ) c > - c > 24 . 4 c > gcnseq ( damonte and cohen , 2019 ) c > - c > 24 . 4 c > c > c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > c > c > 24 . 4 c > 24 . 4 c > 24 . 4 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seq2seqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseqseq
< extra_id_0 > the model size in terms of parameters . gcnseq achieves 24 . 5 bleu points . gcnseq achieves 24 . 5 bleu points . ggnn2seq achieves 24 . 5 bleu points . ggnn2seq achieves 24 . 5 bleu points . ggnn2seq achieves 24 . 5 bleu points . ggnn2seq achieves 24 . 5 bleu points . ggnn2seq achieves 24 . 5 bleu points .
< extra_id_0 > english - czech # p c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german # p c > [ bold ] english - german # p c > [ bold ] c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > [ italic ] n c > [ italic ] m c > [ italic ] n c > [ italic ] m c > [ italic ] n c > [ italic ] n c > [ italic ] m c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] c >
< extra_id_0 > + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc
< extra_id_0 > 20 . 9m c > 52 . 0m c > c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > 420 c > 10 . 9m c > 20 . 9m c > 22 . 8m c > 23 . 8m c >
< extra_id_0 > - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i -
< extra_id_0 > table 9 summarizes the ablation study for modules used in the graph encoder and the lstm decoder . the lstm decoder has a significantly higher ablation rate than the encoder and lstm decoder .
< extra_id_0 > c > initialization c > depth c > objnum c > tense c > glorot c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c >
< extra_id_0 > subjnum c > tense c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst
< extra_id_0 > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c >
< extra_id_0 > c > sts14 c > sts14 c > sts15 c > sts16 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > cmp . c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > cmp .
< extra_id_0 > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c >
< extra_id_0 > c > sts13 c > sts14 c > sts15 c > sts16 c > cmow - c c > [ bold ] 31 . 9 c > [ bold ] 31 . 9 c > [ bold ] 31 . 9 c > [ bold ] 31 . 9 c > [ bold ] 31 . 9 c > [ bold ] 31 . 9 c > [ bold ] 31 . 9 c > [ bold ] 41 . 9 c > [ bold ] 41 . 6 c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold
< extra_id_0 > , < extra_id_1 > method c > bshift c > objnum c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c >
< extra_id_0 > mrpc c > mpqa c > mrpc c > mrpc c > sick - e c > sick - b c > sick - r c > cmow - c c > 79 . 3 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > [ bold ] c > [ bold ] c >
< extra_id_0 > all loc c > all org c > all misc c > all misc c > all org c > all per c > all misc c > all loc c > all org c > all per c > all misc c > all misc c > 96 . 26 c > 89 . 48 c > 89 . 46 c > 89 . 46 c >
< extra_id_0 > all p c > all r c > all f1 c > in [ italic ] e + p c > all p c > in [ italic ] e + r c > in [ italic ] e + f1 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 13 c >
< extra_id_0 > gen ref gen con / bold > gen con / bold > gen ref gen con / bold > gen ref gen con / bold > gen ref gen con / bold > gen ref gen gen s2s
< extra_id_0 > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > g2s -
< extra_id_0 > bold > model / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold >
< extra_id_0 > bold > meteor / bold > bold > size / bold > bold > size / bold > bold > size / bold > bold > size / bold > bold > size / bold > bold > size / bold > bold > size / bold > bold > size / bold > bils
< extra_id_0 > 7 - 13
< extra_id_0 > bold > added / bold > bold > miss / bold > bold > added / bold > bold > miss / bold > bold > added / bold > bold > added / bold > bold > miss / bold > bold > added / bold > bold > added / bold > bold >
< extra_id_0 > table 4 shows sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . sem and pos tagging accuracy are shown in table 4 .
< extra_id_0 > pos and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines .
< extra_id_0 > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh
< extra_id_0 > pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders are shown in table 5 .
< extra_id_0 > task c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > sentiment c > 14 . 3 c > pan16 c > mention c > age c > 9 . 7 c > [ empty ] c > mention c >
< extra_id_0 > task c > accuracy c > 67 . 4 r > [ empty ] c > [ italic ] mention c > 67 . 4 r > [ empty ] c > [ italic ] gender c > 67 . 4 r > [ empty ] c > [ italic ] c > [ italic ] c > [ italic ] gender c > 67 . 4 c >
< extra_id_0 > table 2 : protected attribute leakage : balanced & unbalanced data splits . mention c > 67 . 4 c > 64 . 5 c > 79 . 5 c > 73 . 5 c > unbalanced leakage c > 73 . 5 c > unbalanced leakage c > 73 . 5 c > unbalanced leakage .
< extra_id_0 > data c > protected attribute c > leakage c > [ empty ] c > mention c > gender c > 72 . 5 c > 57 . 3 c > 6 . 9 c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c >
< extra_id_0 > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > guarded c > 59 . 3 c > 54 . 8 c >
< extra_id_0 > ptb + finetune c > ptb + dynamic c > wt2 base c > wt2 + finetune c > wt2 + dynamic c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang
< extra_id_0 > base acc c > + bert acc c > + bert acc c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > + bert time c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > amapolar time c > yahoo err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c >
< extra_id_0 > train c > decode c > train c > train c > train c > decode c > train c > train c > train c > decode c > train c > train c > decode c > train c > decode c > train c > decode c > train c > decode c > decode c > decode c >
< extra_id_0 > “ # params ” : the parameter number of base . “ rnet * ” : the results published by wang et al . ( 2017 ) .
< extra_id_0 > “ # params ” : the parameter number in conll - 2003 english ner task . “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task .
< extra_id_0 > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting . cap > cap > cap > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting .
< extra_id_0 > w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval c > 66 c > 66 c > 66 c > 66 c > 66 c > 66 c > 66 c > 66 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold .
< extra_id_0 > slqs c > docsub c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > slqs c > docsub c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > slqs c > docsub c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > dsim c > slqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > dsim c > slqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > hlqs c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > table 1 shows the performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 .
< extra_id_0 > c > lf c > hciae c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > coatt c > c > c > c > c > c > c > c > c > c > + p1c >
< extra_id_0 > fi - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > cs - en c > bold > direct assessment / bold > fi - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > lv - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > bold > direct assessment / bold > bold > bold > bold > c > bold > bold > bold > bold > / bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold > bold >
< extra_id_0 > inf / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold >
< extra_id_0 > m1 m2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2
< extra_id_0 > 0 . 728 c > 22 . 3 c > 8 . 81 c > gm c > m1 : m0 [ italic ] + cyc + para c > 0 . 788 c > 0 . 747 c > 49 . 9 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > m4 : m0 [ italic ] + cyc + para c > 0 . 754 c > [ bold ] 12 . 8 c > [ bold ] c > [ bold ] c > [ bold ] c > [ cyc + para c > [ cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para cyc + para
< extra_id_0 > transfer quality a > b c > semantic preservation a > b c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie
< extra_id_0 > c > metric c > method of validation c > yelp c > lit . c > acc c > % of machine and human judgments that match c > 94 c > 84 c > spearman ’ s [ italic ] b / w negative pp and human ratings of fluency c > 0 . 81 c > 0 . 67 c > 0 . 67 c > 0 . 67 c >
< extra_id_0 > 37 . 3 c > 10 . 0 c > gm c > acc c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m1 : m0 [ italic ] + para c >
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work at similar levels of acc , but untransferred sentences achieve the highest bleu than previous work at similar levels of bleu . bleu is between 1000 transferred sentences and human references , and bleu is between 1000 transferred sentences and human references . our best models achieve higher bleu than previous work , but untransferred sentences achieve the highest bleu .
< extra_id_0 > 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] – c > 0 . 39 . repar
< extra_id_0 > 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > [ bold ] reparandum length [ bold ] 3 - 5 c > content - content c > 0 . 61 ( 30 % ) c > 0 . 58 ( 52 % ) c > 0 . 58 ( 52 % ) c > 0 . 81 ( 32 % ) c > 0 . 80 ( 32 % ) c >
< extra_id_0 > c > [ bold ] dev mean c > [ bold ] dev best c > [ italic ] c > [ empty ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > early c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > our model c > 28 . 53 c > 65 . 43 c > 65 . 43 c > 81 . 72 c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ]
< extra_id_0 > cap > table 2 : accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models ( higher is better ) .
< extra_id_0 > table 3 shows the accuracy ( % ) comparisons of component models with and without attention . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] all c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empt
< extra_id_0 > ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] f1 c > [ italic ] p c > [ italic ] p c > [ italic ] f1 c > [ italic ] f1 c > [ italic ] f1 c > [ italic ] classification ( % ) c > [ italic ] f1 c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c >
< extra_id_0 > wer
< extra_id_0 > train dev c > 50 % train dev c > 50 % train test c > 75 % train dev c > full train test c > 75 % train dev c > cs - only c > cs - only c > 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] 73 . 0 c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > cs - only c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
cap > table 5 : accuracy on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset , the conll - 2003 dataset scores significantly better than baseline .
< extra_id_0 > c > [ bold ] conll - 2003 c > [ bold ] p c > [ bold ] r c > [ bold ] f1 - score ( f1 ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) c > baseline c > 93 . 89 c > 94 . 16 c > 94 . 03 c > [ bold ] f1 -
< extra_id_0 > table 1 shows the results on belinkov2014exploring ’ s ppa test set . syntactic skipgram is used to initialize the glove vectors , and ontolstm - pp is used to extend the glove embeddings . ontolstm - pp is used to extend the glove embeddings .
< extra_id_0 > c > [ bold ] full uas c > [ bold ] ppa acc . c > [ bold ] full uas c > [ bold ] ppa acc . c > [ bold ] full uas c > [ bold ] ppa acc . c > 94 . 17 c > 88 . 51 c > rbg + hpcd ( full ) c > 94 . 19 c >
< extra_id_0 > c > [ bold ] ppa acc . r > 89 . 7 c > - sense priors c > 88 . 4 c > - attention c > 87 . 5 cap > effect of removing sense priors and context sensitivity ( attention ) from the model .
< extra_id_0 > c > en - fr c > flickr16 c > mscoco17 c > mscoco17 c > en - fr c > en - de c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > en - fr c > en - de c > en - fr c >
< extra_id_0 > mscoco17 c > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > c >
< extra_id_0 > table 4 shows that en - fr and mscoco17 perform better than en - fr and mscoco17 and mscoco17 . however , en - fr and mscoco17 perform better than en - fr and flickr16 and flickr17 and mscoco17 and mscoco17 , respectively .
< extra_id_0 > mscoco17 and en - de c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > enc - gate c > enc - gate c > enc - gate c > dec - gate
< extra_id_0 > mscoco17 c > en - fr c > flickr16 c > mscoco17 c > mscoco17 c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > mscoco17 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > < extra_id_1 > > yule ’ s i c > ttr c > yule ’ s i c > yule ’ s i c > yule ’ s i c > mtld c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . the number of parallel sentences in the train , test and development splits for the language pairs we used is shown in table 1 .
< extra_id_0 > r > c > src c > trg r > c > training vocabularies for the english , french and spanish data used for our models . training vocabularies for the english , french and spanish data used for our models .
< extra_id_0 > c > en - fr - rnn - rev c > 33 . 3 c > 50 . 2 c > en - fr - trans - rev c > 36 . 5 c > 47 . 1 c > en - fr - trans - rev c > 42 . 9 c > en - fr - trans - rev c > 42 . 7 c > en - fr - trans - rev c >
< extra_id_0 > c > [ empty ] c > recall @ 10 ( % ) c > [ empty ] c > recall @ 10 ( % ) c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > vgs c > 15 c > 17 c > 0 . 0 c > mfcc
< extra_id_0 > c > [ empty ] c > recall @ 10 ( % ) c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c
< extra_id_0 > she turns in a u > screenplay screenplay that u > at the edges ; it ’ s so clever you want hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate
< extra_id_0 > < extra_id_1 > bold > rnn / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > / bold > bold >
< extra_id_0 > bold > rnn / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold >
< extra_id_0 > bold > sst - 2 / bold > positive bold > sst - 2 / bold > negative bold > pubmed / bold > bold > pmi / bold > bold > pmi / bold > bold > pmi / bold > bold > pmi / bold > bold > pmi / bold > bold > pmi /
